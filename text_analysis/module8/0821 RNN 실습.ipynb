{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wikidocs.net/22886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('https://wikidocs.net/images/page/22886/rnn_image6between7.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape = (2,10)))\n",
    "#model.add(SimpleRNN(3, input_length = 2, input_dim=10))과 동일\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "헷갈리지 말아야할 점은 위의 코드는 출력층까지 포함한 하나의 완성된 인공 신경망 코드가 아니라 은닉층. 즉, RNN 층에 대한 코드라는 점입니다. 해당 코드가 리턴하는 결과값은 출력층의 결과가 아니라 하나의 은닉 상태 또는 정의하기에 따라 다수의 은닉 상태 입니다. 아래의 그림은 앞서 배운 출력층을 포함한 완성된 인공 신경망 그림과 은닉층까지만 표현한 그림의 차이를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('https://wikidocs.net/images/page/22886/rnn_image7_ver2.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 RNN 층은 위에서 설명한 입력 3D 텐서를 입력받아서 어떻게 은닉 상태를 출력할까요? RNN 층은 사용자의 설정에 따라 두 가지 종류의 출력을 내보냅니다. 메모리 셀의 최종 시점의 은닉 상태만을 리턴하고자 한다면 (batch_size, output_dim) 크기의 2D 텐서를 리턴합니다. 하지만, 메모리 셀의 각 시점(time-step)의 은닉 상태값들을 모아서 전체 시퀀스를 리턴하고자 한다면 (batch_size, timesteps, output_dim) 크기의 3D 텐서를 리턴합니다. 이는 RNN 층의 return_sequences 매개 변수에 True를 설정하여 설정이 가능합니다. (output_dim은 앞서 코드에서 정의한 hidden_size의 값으로 설정됩니다.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('https://wikidocs.net/images/page/22886/rnn_image8_ver2.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size를 미리 정의하지 않았기 때문에 (None, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (8, 3)                    42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#batch_size를 미리 정의\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape = (8,2,10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return_sequences=True를 선택하면 메모리 셀이 모든 시점(time-step)에 대해서 은닉 상태값을 출력하며, 별도 기재하지 않거나 return_sequences=False로 선택할 경우에는 메모리 셀은 하나의 은닉 상태값만을 출력합니다. 그리고 이 하나의 값은 마지막 시점(time-step)의 메모리 셀의 은닉 상태값입니다.\n",
    "\n",
    "마지막 은닉 상태만 전달하도록 하면 many-to-one 문제를 풀 수 있고, 모든 시점의 은닉 상태를 전달하도록 하면, 다음층에 은닉층이 하나 더 있는 경우이거나 many-to-many 문제를 풀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (8, 2, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 출력값으로 (batch_size, timesteps, output_dim) 크기의 3D 텐서를 리턴\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape = (8,2,10), return_sequences = True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 양방향 순환 신경망 Bidirectional Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "양방향 RNN은 하나의 출력값을 예측하기 위해 기본적으로 두 개의 메모리 셀을 사용합니다. 첫번째 메모리 셀은 앞에서 배운 것처럼 앞 시점의 은닉 상태(Forward States)를 전달받아 현재의 은닉 상태를 계산합니다. 두번째 메모리 셀은 앞에서 배운 것과는 다릅니다. 앞 시점의 은닉 상태가 아니라 뒤 시점의 은닉 상태(Backward States)를 전달 받아 현재의 은닉 상태를 계산합니다. 그리고 이 두 개의 값 모두가 하나의 출력값을 예측하기 위해 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image('https://wikidocs.net/images/page/22886/rnn_image5_ver2.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가벼운 실습. 실제 모델 구현 목적보다는 모델링 이해를 위한 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "# tf.enable_eager_execution() 시작 때 수행되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X=[[0.1,4.2,1.5,1.1,2.8],[1.0,3.1,2.5,0.7,1.1],[0.3,2.1,1.5,.1,2],[2.2,1.4,.5,.9,1.1]]\n",
    "np.shape(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(input_length, input_dim)의 크기에 해당됨. 여기서 input_length는 곧 시점(timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RNN은 3D 텐서를 입력받기 때문에 3D텐서로 변경\n",
    "train_X = [train_X]\n",
    "train_X = np.array(train_X, dtype = np.float32)\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(batch_size(문장 개수), timesteps, input_dim)에 해당되는 (1,4,5) 의 크기를 가지는 3D 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=2542, shape=(1, 4, 3), dtype=float32, numpy=\n",
       " array([[[-0.9998839 , -0.9504982 , -0.9998037 ],\n",
       "         [-0.9796907 , -0.9817744 , -0.9999917 ],\n",
       "         [-0.8708688 , -0.244085  , -0.99963355],\n",
       "         [-0.8093793 , -0.99007994, -0.9997992 ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=2528, shape=(1, 3), dtype=float32, numpy=array([[-0.8093793 , -0.99007994, -0.9997992 ]], dtype=float32)>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn =SimpleRNN(3, return_sequences= True, return_state= True) # return_state : 마지막 은닉 상태를 리턴 / return_sequences : 모든 시점에 대해 을 리턴\n",
    "hidden_states, last_states = rnn(train_X)\n",
    "rnn(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=515, shape=(1, 3), dtype=float32, numpy=array([[-0.68355626, -0.617126  , -0.94395345]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn =SimpleRNN(3)\n",
    "rnn(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=689, shape=(1, 4, 3), dtype=float32, numpy=\n",
       "array([[[0.9891739 , 0.9999545 , 0.99795514],\n",
       "        [0.9962509 , 0.9999231 , 0.98900497],\n",
       "        [0.93906444, 0.99960136, 0.8675098 ],\n",
       "        [0.9980718 , 0.9992328 , 0.946656  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn=SimpleRNN(3, return_sequences= True)\n",
    "rnn(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1896, shape=(1, 3), dtype=float32, numpy=array([[ 0.14483131, -0.8721752 , -0.41330364]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn2=SimpleRNN(3, return_sequences=False)\n",
    "rnn2(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN을 이용한 언어 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한국어 문장을 선언\n",
    "text = \"나랑 점심 먹으러 갈래 메뉴는 햄버거 점심 메뉴 좋지\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화와 정수 인코딩\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "encoded = t.texts_to_sequences([text])[0] \n",
    "# [0]을 해주지 않으면 [[contents]]와 같이 리스트 안 리스트로 저장 됨 / [0]을 하면 [content]로 하나의 원소를 가진 리스트로 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "#케라스 토크나이저의 정수 인코딩은 인덱스가 1부터 시작하지만, 원-핫 인코딩에서 배열의 인덱스가 0부터 시작하기 때문에\n",
    "#배열의 크기를 실제 단어 집합 크기보다 +1로 생성해야 하므로 미리 +1 선언\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'점심': 1, '나랑': 2, '먹으러': 3, '갈래': 4, '메뉴는': 5, '햄버거': 6, '메뉴': 7, '좋지': 8}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장에서 두 개 단어씩 묶어주기 - 문장의 bigram을 추출한다고 봐도 무방함\n",
    "sequences = list()\n",
    "for c in range(1,len(encoded)) :\n",
    "    sequence = encoded[c-1:c+1] # X, Y 관계를 구성하기 위해 단어를 두 개씩 묶어서 저장해줌\n",
    "    sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1], [1, 3], [3, 4], [4, 5], [5, 6], [6, 1], [1, 7], [7, 8]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#출력\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#첫번째 열과 두번째 열을 X와 y에 저장하는 코드\n",
    "import numpy as np\n",
    "X, y = zip(*sequences) # 1st 열 : X, 2nd 열 : y  / 세 개 이상 원소를 가지는 경우, 각 열마다 하나의 리스트로 뭉쳐짐\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes = vocab_size) # 원-핫 인코딩\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, Dense, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 9, input_length = 1))\n",
    "#단어 집합 크기 : 9,, 임베딩 벡터 크기 : 9 (크지 않아 동일하게 설정. 보통 더 적게 설정), 각 sample의 길이는 단어 한 개이므로 길이 1\n",
    "model.add(SimpleRNN(5))\n",
    "#RNN 결과값도 차원 9. 더 크게 해줘도 상관 없음\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "#출력층을 지나 나오는 벡터의 크기도 9로 한다.\n",
    "\n",
    "\n",
    "# SimpleRNN에 하나의 값을 인자로 줄 때, 이 값은 time-step이 아니라 hidden-size의 값, 즉 outuput_dim을 정의해준 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 1s - loss: 2.1992 - acc: 0.1250\n",
      "Epoch 2/500\n",
      " - 0s - loss: 2.1963 - acc: 0.2500\n",
      "Epoch 3/500\n",
      " - 0s - loss: 2.1934 - acc: 0.1250\n",
      "Epoch 4/500\n",
      " - 0s - loss: 2.1905 - acc: 0.2500\n",
      "Epoch 5/500\n",
      " - 0s - loss: 2.1876 - acc: 0.2500\n",
      "Epoch 6/500\n",
      " - 0s - loss: 2.1848 - acc: 0.2500\n",
      "Epoch 7/500\n",
      " - 0s - loss: 2.1819 - acc: 0.2500\n",
      "Epoch 8/500\n",
      " - 0s - loss: 2.1791 - acc: 0.2500\n",
      "Epoch 9/500\n",
      " - 0s - loss: 2.1762 - acc: 0.2500\n",
      "Epoch 10/500\n",
      " - 0s - loss: 2.1733 - acc: 0.2500\n",
      "Epoch 11/500\n",
      " - 0s - loss: 2.1705 - acc: 0.2500\n",
      "Epoch 12/500\n",
      " - 0s - loss: 2.1676 - acc: 0.2500\n",
      "Epoch 13/500\n",
      " - 0s - loss: 2.1647 - acc: 0.3750\n",
      "Epoch 14/500\n",
      " - 0s - loss: 2.1618 - acc: 0.3750\n",
      "Epoch 15/500\n",
      " - 0s - loss: 2.1589 - acc: 0.3750\n",
      "Epoch 16/500\n",
      " - 0s - loss: 2.1559 - acc: 0.3750\n",
      "Epoch 17/500\n",
      " - 0s - loss: 2.1530 - acc: 0.3750\n",
      "Epoch 18/500\n",
      " - 0s - loss: 2.1500 - acc: 0.3750\n",
      "Epoch 19/500\n",
      " - 0s - loss: 2.1470 - acc: 0.3750\n",
      "Epoch 20/500\n",
      " - 0s - loss: 2.1440 - acc: 0.3750\n",
      "Epoch 21/500\n",
      " - 0s - loss: 2.1410 - acc: 0.3750\n",
      "Epoch 22/500\n",
      " - 0s - loss: 2.1379 - acc: 0.3750\n",
      "Epoch 23/500\n",
      " - 0s - loss: 2.1348 - acc: 0.3750\n",
      "Epoch 24/500\n",
      " - 0s - loss: 2.1317 - acc: 0.3750\n",
      "Epoch 25/500\n",
      " - 0s - loss: 2.1286 - acc: 0.3750\n",
      "Epoch 26/500\n",
      " - 0s - loss: 2.1254 - acc: 0.3750\n",
      "Epoch 27/500\n",
      " - 0s - loss: 2.1222 - acc: 0.3750\n",
      "Epoch 28/500\n",
      " - 0s - loss: 2.1190 - acc: 0.3750\n",
      "Epoch 29/500\n",
      " - 0s - loss: 2.1158 - acc: 0.3750\n",
      "Epoch 30/500\n",
      " - 0s - loss: 2.1125 - acc: 0.3750\n",
      "Epoch 31/500\n",
      " - 0s - loss: 2.1091 - acc: 0.5000\n",
      "Epoch 32/500\n",
      " - 0s - loss: 2.1058 - acc: 0.5000\n",
      "Epoch 33/500\n",
      " - 0s - loss: 2.1024 - acc: 0.5000\n",
      "Epoch 34/500\n",
      " - 0s - loss: 2.0990 - acc: 0.5000\n",
      "Epoch 35/500\n",
      " - 0s - loss: 2.0955 - acc: 0.5000\n",
      "Epoch 36/500\n",
      " - 0s - loss: 2.0921 - acc: 0.5000\n",
      "Epoch 37/500\n",
      " - 0s - loss: 2.0885 - acc: 0.5000\n",
      "Epoch 38/500\n",
      " - 0s - loss: 2.0850 - acc: 0.5000\n",
      "Epoch 39/500\n",
      " - 0s - loss: 2.0814 - acc: 0.5000\n",
      "Epoch 40/500\n",
      " - 0s - loss: 2.0777 - acc: 0.5000\n",
      "Epoch 41/500\n",
      " - 0s - loss: 2.0741 - acc: 0.5000\n",
      "Epoch 42/500\n",
      " - 0s - loss: 2.0704 - acc: 0.5000\n",
      "Epoch 43/500\n",
      " - 0s - loss: 2.0666 - acc: 0.5000\n",
      "Epoch 44/500\n",
      " - 0s - loss: 2.0628 - acc: 0.5000\n",
      "Epoch 45/500\n",
      " - 0s - loss: 2.0590 - acc: 0.5000\n",
      "Epoch 46/500\n",
      " - 0s - loss: 2.0551 - acc: 0.5000\n",
      "Epoch 47/500\n",
      " - 0s - loss: 2.0512 - acc: 0.5000\n",
      "Epoch 48/500\n",
      " - 0s - loss: 2.0473 - acc: 0.5000\n",
      "Epoch 49/500\n",
      " - 0s - loss: 2.0433 - acc: 0.5000\n",
      "Epoch 50/500\n",
      " - 0s - loss: 2.0393 - acc: 0.5000\n",
      "Epoch 51/500\n",
      " - 0s - loss: 2.0352 - acc: 0.5000\n",
      "Epoch 52/500\n",
      " - 0s - loss: 2.0311 - acc: 0.5000\n",
      "Epoch 53/500\n",
      " - 0s - loss: 2.0270 - acc: 0.5000\n",
      "Epoch 54/500\n",
      " - 0s - loss: 2.0228 - acc: 0.5000\n",
      "Epoch 55/500\n",
      " - 0s - loss: 2.0186 - acc: 0.5000\n",
      "Epoch 56/500\n",
      " - 0s - loss: 2.0144 - acc: 0.5000\n",
      "Epoch 57/500\n",
      " - 0s - loss: 2.0101 - acc: 0.5000\n",
      "Epoch 58/500\n",
      " - 0s - loss: 2.0057 - acc: 0.5000\n",
      "Epoch 59/500\n",
      " - 0s - loss: 2.0014 - acc: 0.5000\n",
      "Epoch 60/500\n",
      " - 0s - loss: 1.9969 - acc: 0.5000\n",
      "Epoch 61/500\n",
      " - 0s - loss: 1.9925 - acc: 0.5000\n",
      "Epoch 62/500\n",
      " - 0s - loss: 1.9880 - acc: 0.5000\n",
      "Epoch 63/500\n",
      " - 0s - loss: 1.9835 - acc: 0.5000\n",
      "Epoch 64/500\n",
      " - 0s - loss: 1.9789 - acc: 0.5000\n",
      "Epoch 65/500\n",
      " - 0s - loss: 1.9743 - acc: 0.5000\n",
      "Epoch 66/500\n",
      " - 0s - loss: 1.9697 - acc: 0.5000\n",
      "Epoch 67/500\n",
      " - 0s - loss: 1.9650 - acc: 0.5000\n",
      "Epoch 68/500\n",
      " - 0s - loss: 1.9603 - acc: 0.5000\n",
      "Epoch 69/500\n",
      " - 0s - loss: 1.9555 - acc: 0.5000\n",
      "Epoch 70/500\n",
      " - 0s - loss: 1.9507 - acc: 0.5000\n",
      "Epoch 71/500\n",
      " - 0s - loss: 1.9459 - acc: 0.5000\n",
      "Epoch 72/500\n",
      " - 0s - loss: 1.9410 - acc: 0.5000\n",
      "Epoch 73/500\n",
      " - 0s - loss: 1.9361 - acc: 0.5000\n",
      "Epoch 74/500\n",
      " - 0s - loss: 1.9312 - acc: 0.5000\n",
      "Epoch 75/500\n",
      " - 0s - loss: 1.9262 - acc: 0.5000\n",
      "Epoch 76/500\n",
      " - 0s - loss: 1.9213 - acc: 0.5000\n",
      "Epoch 77/500\n",
      " - 0s - loss: 1.9162 - acc: 0.5000\n",
      "Epoch 78/500\n",
      " - 0s - loss: 1.9112 - acc: 0.5000\n",
      "Epoch 79/500\n",
      " - 0s - loss: 1.9061 - acc: 0.5000\n",
      "Epoch 80/500\n",
      " - 0s - loss: 1.9009 - acc: 0.5000\n",
      "Epoch 81/500\n",
      " - 0s - loss: 1.8958 - acc: 0.5000\n",
      "Epoch 82/500\n",
      " - 0s - loss: 1.8906 - acc: 0.5000\n",
      "Epoch 83/500\n",
      " - 0s - loss: 1.8854 - acc: 0.5000\n",
      "Epoch 84/500\n",
      " - 0s - loss: 1.8802 - acc: 0.5000\n",
      "Epoch 85/500\n",
      " - 0s - loss: 1.8749 - acc: 0.5000\n",
      "Epoch 86/500\n",
      " - 0s - loss: 1.8696 - acc: 0.5000\n",
      "Epoch 87/500\n",
      " - 0s - loss: 1.8643 - acc: 0.5000\n",
      "Epoch 88/500\n",
      " - 0s - loss: 1.8589 - acc: 0.5000\n",
      "Epoch 89/500\n",
      " - 0s - loss: 1.8536 - acc: 0.5000\n",
      "Epoch 90/500\n",
      " - 0s - loss: 1.8482 - acc: 0.5000\n",
      "Epoch 91/500\n",
      " - 0s - loss: 1.8427 - acc: 0.5000\n",
      "Epoch 92/500\n",
      " - 0s - loss: 1.8373 - acc: 0.5000\n",
      "Epoch 93/500\n",
      " - 0s - loss: 1.8318 - acc: 0.5000\n",
      "Epoch 94/500\n",
      " - 0s - loss: 1.8264 - acc: 0.5000\n",
      "Epoch 95/500\n",
      " - 0s - loss: 1.8209 - acc: 0.5000\n",
      "Epoch 96/500\n",
      " - 0s - loss: 1.8153 - acc: 0.5000\n",
      "Epoch 97/500\n",
      " - 0s - loss: 1.8098 - acc: 0.5000\n",
      "Epoch 98/500\n",
      " - 0s - loss: 1.8042 - acc: 0.5000\n",
      "Epoch 99/500\n",
      " - 0s - loss: 1.7987 - acc: 0.5000\n",
      "Epoch 100/500\n",
      " - 0s - loss: 1.7931 - acc: 0.5000\n",
      "Epoch 101/500\n",
      " - 0s - loss: 1.7874 - acc: 0.5000\n",
      "Epoch 102/500\n",
      " - 0s - loss: 1.7818 - acc: 0.5000\n",
      "Epoch 103/500\n",
      " - 0s - loss: 1.7762 - acc: 0.5000\n",
      "Epoch 104/500\n",
      " - 0s - loss: 1.7705 - acc: 0.5000\n",
      "Epoch 105/500\n",
      " - 0s - loss: 1.7649 - acc: 0.5000\n",
      "Epoch 106/500\n",
      " - 0s - loss: 1.7592 - acc: 0.5000\n",
      "Epoch 107/500\n",
      " - 0s - loss: 1.7535 - acc: 0.5000\n",
      "Epoch 108/500\n",
      " - 0s - loss: 1.7478 - acc: 0.5000\n",
      "Epoch 109/500\n",
      " - 0s - loss: 1.7421 - acc: 0.5000\n",
      "Epoch 110/500\n",
      " - 0s - loss: 1.7364 - acc: 0.5000\n",
      "Epoch 111/500\n",
      " - 0s - loss: 1.7307 - acc: 0.5000\n",
      "Epoch 112/500\n",
      " - 0s - loss: 1.7249 - acc: 0.5000\n",
      "Epoch 113/500\n",
      " - 0s - loss: 1.7192 - acc: 0.5000\n",
      "Epoch 114/500\n",
      " - 0s - loss: 1.7135 - acc: 0.5000\n",
      "Epoch 115/500\n",
      " - 0s - loss: 1.7077 - acc: 0.5000\n",
      "Epoch 116/500\n",
      " - 0s - loss: 1.7020 - acc: 0.5000\n",
      "Epoch 117/500\n",
      " - 0s - loss: 1.6962 - acc: 0.5000\n",
      "Epoch 118/500\n",
      " - 0s - loss: 1.6904 - acc: 0.5000\n",
      "Epoch 119/500\n",
      " - 0s - loss: 1.6847 - acc: 0.5000\n",
      "Epoch 120/500\n",
      " - 0s - loss: 1.6789 - acc: 0.5000\n",
      "Epoch 121/500\n",
      " - 0s - loss: 1.6732 - acc: 0.5000\n",
      "Epoch 122/500\n",
      " - 0s - loss: 1.6674 - acc: 0.5000\n",
      "Epoch 123/500\n",
      " - 0s - loss: 1.6616 - acc: 0.5000\n",
      "Epoch 124/500\n",
      " - 0s - loss: 1.6559 - acc: 0.5000\n",
      "Epoch 125/500\n",
      " - 0s - loss: 1.6501 - acc: 0.5000\n",
      "Epoch 126/500\n",
      " - 0s - loss: 1.6444 - acc: 0.5000\n",
      "Epoch 127/500\n",
      " - 0s - loss: 1.6386 - acc: 0.5000\n",
      "Epoch 128/500\n",
      " - 0s - loss: 1.6329 - acc: 0.5000\n",
      "Epoch 129/500\n",
      " - 0s - loss: 1.6271 - acc: 0.5000\n",
      "Epoch 130/500\n",
      " - 0s - loss: 1.6214 - acc: 0.5000\n",
      "Epoch 131/500\n",
      " - 0s - loss: 1.6156 - acc: 0.5000\n",
      "Epoch 132/500\n",
      " - 0s - loss: 1.6099 - acc: 0.6250\n",
      "Epoch 133/500\n",
      " - 0s - loss: 1.6042 - acc: 0.6250\n",
      "Epoch 134/500\n",
      " - 0s - loss: 1.5984 - acc: 0.6250\n",
      "Epoch 135/500\n",
      " - 0s - loss: 1.5927 - acc: 0.6250\n",
      "Epoch 136/500\n",
      " - 0s - loss: 1.5870 - acc: 0.6250\n",
      "Epoch 137/500\n",
      " - 0s - loss: 1.5813 - acc: 0.6250\n",
      "Epoch 138/500\n",
      " - 0s - loss: 1.5756 - acc: 0.6250\n",
      "Epoch 139/500\n",
      " - 0s - loss: 1.5700 - acc: 0.6250\n",
      "Epoch 140/500\n",
      " - 0s - loss: 1.5643 - acc: 0.6250\n",
      "Epoch 141/500\n",
      " - 0s - loss: 1.5586 - acc: 0.6250\n",
      "Epoch 142/500\n",
      " - 0s - loss: 1.5530 - acc: 0.6250\n",
      "Epoch 143/500\n",
      " - 0s - loss: 1.5474 - acc: 0.6250\n",
      "Epoch 144/500\n",
      " - 0s - loss: 1.5417 - acc: 0.6250\n",
      "Epoch 145/500\n",
      " - 0s - loss: 1.5361 - acc: 0.6250\n",
      "Epoch 146/500\n",
      " - 0s - loss: 1.5305 - acc: 0.6250\n",
      "Epoch 147/500\n",
      " - 0s - loss: 1.5249 - acc: 0.6250\n",
      "Epoch 148/500\n",
      " - 0s - loss: 1.5193 - acc: 0.6250\n",
      "Epoch 149/500\n",
      " - 0s - loss: 1.5138 - acc: 0.6250\n",
      "Epoch 150/500\n",
      " - 0s - loss: 1.5082 - acc: 0.6250\n",
      "Epoch 151/500\n",
      " - 0s - loss: 1.5027 - acc: 0.6250\n",
      "Epoch 152/500\n",
      " - 0s - loss: 1.4972 - acc: 0.7500\n",
      "Epoch 153/500\n",
      " - 0s - loss: 1.4916 - acc: 0.7500\n",
      "Epoch 154/500\n",
      " - 0s - loss: 1.4861 - acc: 0.7500\n",
      "Epoch 155/500\n",
      " - 0s - loss: 1.4807 - acc: 0.7500\n",
      "Epoch 156/500\n",
      " - 0s - loss: 1.4752 - acc: 0.7500\n",
      "Epoch 157/500\n",
      " - 0s - loss: 1.4698 - acc: 0.7500\n",
      "Epoch 158/500\n",
      " - 0s - loss: 1.4643 - acc: 0.7500\n",
      "Epoch 159/500\n",
      " - 0s - loss: 1.4589 - acc: 0.7500\n",
      "Epoch 160/500\n",
      " - 0s - loss: 1.4535 - acc: 0.7500\n",
      "Epoch 161/500\n",
      " - 0s - loss: 1.4481 - acc: 0.7500\n",
      "Epoch 162/500\n",
      " - 0s - loss: 1.4428 - acc: 0.7500\n",
      "Epoch 163/500\n",
      " - 0s - loss: 1.4374 - acc: 0.7500\n",
      "Epoch 164/500\n",
      " - 0s - loss: 1.4321 - acc: 0.7500\n",
      "Epoch 165/500\n",
      " - 0s - loss: 1.4268 - acc: 0.7500\n",
      "Epoch 166/500\n",
      " - 0s - loss: 1.4215 - acc: 0.7500\n",
      "Epoch 167/500\n",
      " - 0s - loss: 1.4162 - acc: 0.7500\n",
      "Epoch 168/500\n",
      " - 0s - loss: 1.4109 - acc: 0.7500\n",
      "Epoch 169/500\n",
      " - 0s - loss: 1.4057 - acc: 0.7500\n",
      "Epoch 170/500\n",
      " - 0s - loss: 1.4005 - acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500\n",
      " - 0s - loss: 1.3953 - acc: 0.7500\n",
      "Epoch 172/500\n",
      " - 0s - loss: 1.3901 - acc: 0.7500\n",
      "Epoch 173/500\n",
      " - 0s - loss: 1.3849 - acc: 0.7500\n",
      "Epoch 174/500\n",
      " - 0s - loss: 1.3797 - acc: 0.7500\n",
      "Epoch 175/500\n",
      " - 0s - loss: 1.3746 - acc: 0.7500\n",
      "Epoch 176/500\n",
      " - 0s - loss: 1.3695 - acc: 0.7500\n",
      "Epoch 177/500\n",
      " - 0s - loss: 1.3644 - acc: 0.7500\n",
      "Epoch 178/500\n",
      " - 0s - loss: 1.3593 - acc: 0.7500\n",
      "Epoch 179/500\n",
      " - 0s - loss: 1.3543 - acc: 0.7500\n",
      "Epoch 180/500\n",
      " - 0s - loss: 1.3493 - acc: 0.7500\n",
      "Epoch 181/500\n",
      " - 0s - loss: 1.3442 - acc: 0.7500\n",
      "Epoch 182/500\n",
      " - 0s - loss: 1.3393 - acc: 0.7500\n",
      "Epoch 183/500\n",
      " - 0s - loss: 1.3343 - acc: 0.7500\n",
      "Epoch 184/500\n",
      " - 0s - loss: 1.3293 - acc: 0.7500\n",
      "Epoch 185/500\n",
      " - 0s - loss: 1.3244 - acc: 0.7500\n",
      "Epoch 186/500\n",
      " - 0s - loss: 1.3195 - acc: 0.7500\n",
      "Epoch 187/500\n",
      " - 0s - loss: 1.3146 - acc: 0.7500\n",
      "Epoch 188/500\n",
      " - 0s - loss: 1.3097 - acc: 0.7500\n",
      "Epoch 189/500\n",
      " - 0s - loss: 1.3048 - acc: 0.7500\n",
      "Epoch 190/500\n",
      " - 0s - loss: 1.3000 - acc: 0.7500\n",
      "Epoch 191/500\n",
      " - 0s - loss: 1.2952 - acc: 0.7500\n",
      "Epoch 192/500\n",
      " - 0s - loss: 1.2904 - acc: 0.7500\n",
      "Epoch 193/500\n",
      " - 0s - loss: 1.2856 - acc: 0.7500\n",
      "Epoch 194/500\n",
      " - 0s - loss: 1.2808 - acc: 0.7500\n",
      "Epoch 195/500\n",
      " - 0s - loss: 1.2761 - acc: 0.7500\n",
      "Epoch 196/500\n",
      " - 0s - loss: 1.2714 - acc: 0.7500\n",
      "Epoch 197/500\n",
      " - 0s - loss: 1.2667 - acc: 0.7500\n",
      "Epoch 198/500\n",
      " - 0s - loss: 1.2620 - acc: 0.7500\n",
      "Epoch 199/500\n",
      " - 0s - loss: 1.2573 - acc: 0.7500\n",
      "Epoch 200/500\n",
      " - 0s - loss: 1.2527 - acc: 0.7500\n",
      "Epoch 201/500\n",
      " - 0s - loss: 1.2480 - acc: 0.7500\n",
      "Epoch 202/500\n",
      " - 0s - loss: 1.2434 - acc: 0.7500\n",
      "Epoch 203/500\n",
      " - 0s - loss: 1.2388 - acc: 0.7500\n",
      "Epoch 204/500\n",
      " - 0s - loss: 1.2342 - acc: 0.7500\n",
      "Epoch 205/500\n",
      " - 0s - loss: 1.2297 - acc: 0.7500\n",
      "Epoch 206/500\n",
      " - 0s - loss: 1.2251 - acc: 0.7500\n",
      "Epoch 207/500\n",
      " - 0s - loss: 1.2206 - acc: 0.7500\n",
      "Epoch 208/500\n",
      " - 0s - loss: 1.2161 - acc: 0.7500\n",
      "Epoch 209/500\n",
      " - 0s - loss: 1.2116 - acc: 0.7500\n",
      "Epoch 210/500\n",
      " - 0s - loss: 1.2071 - acc: 0.7500\n",
      "Epoch 211/500\n",
      " - 0s - loss: 1.2027 - acc: 0.7500\n",
      "Epoch 212/500\n",
      " - 0s - loss: 1.1982 - acc: 0.7500\n",
      "Epoch 213/500\n",
      " - 0s - loss: 1.1938 - acc: 0.7500\n",
      "Epoch 214/500\n",
      " - 0s - loss: 1.1894 - acc: 0.7500\n",
      "Epoch 215/500\n",
      " - 0s - loss: 1.1850 - acc: 0.7500\n",
      "Epoch 216/500\n",
      " - 0s - loss: 1.1806 - acc: 0.7500\n",
      "Epoch 217/500\n",
      " - 0s - loss: 1.1763 - acc: 0.7500\n",
      "Epoch 218/500\n",
      " - 0s - loss: 1.1719 - acc: 0.7500\n",
      "Epoch 219/500\n",
      " - 0s - loss: 1.1676 - acc: 0.7500\n",
      "Epoch 220/500\n",
      " - 0s - loss: 1.1633 - acc: 0.7500\n",
      "Epoch 221/500\n",
      " - 0s - loss: 1.1590 - acc: 0.7500\n",
      "Epoch 222/500\n",
      " - 0s - loss: 1.1547 - acc: 0.7500\n",
      "Epoch 223/500\n",
      " - 0s - loss: 1.1504 - acc: 0.7500\n",
      "Epoch 224/500\n",
      " - 0s - loss: 1.1461 - acc: 0.7500\n",
      "Epoch 225/500\n",
      " - 0s - loss: 1.1419 - acc: 0.7500\n",
      "Epoch 226/500\n",
      " - 0s - loss: 1.1377 - acc: 0.7500\n",
      "Epoch 227/500\n",
      " - 0s - loss: 1.1335 - acc: 0.7500\n",
      "Epoch 228/500\n",
      " - 0s - loss: 1.1292 - acc: 0.7500\n",
      "Epoch 229/500\n",
      " - 0s - loss: 1.1251 - acc: 0.7500\n",
      "Epoch 230/500\n",
      " - 0s - loss: 1.1209 - acc: 0.7500\n",
      "Epoch 231/500\n",
      " - 0s - loss: 1.1167 - acc: 0.7500\n",
      "Epoch 232/500\n",
      " - 0s - loss: 1.1126 - acc: 0.7500\n",
      "Epoch 233/500\n",
      " - 0s - loss: 1.1084 - acc: 0.7500\n",
      "Epoch 234/500\n",
      " - 0s - loss: 1.1043 - acc: 0.7500\n",
      "Epoch 235/500\n",
      " - 0s - loss: 1.1002 - acc: 0.7500\n",
      "Epoch 236/500\n",
      " - 0s - loss: 1.0961 - acc: 0.7500\n",
      "Epoch 237/500\n",
      " - 0s - loss: 1.0920 - acc: 0.7500\n",
      "Epoch 238/500\n",
      " - 0s - loss: 1.0879 - acc: 0.7500\n",
      "Epoch 239/500\n",
      " - 0s - loss: 1.0838 - acc: 0.7500\n",
      "Epoch 240/500\n",
      " - 0s - loss: 1.0798 - acc: 0.7500\n",
      "Epoch 241/500\n",
      " - 0s - loss: 1.0757 - acc: 0.7500\n",
      "Epoch 242/500\n",
      " - 0s - loss: 1.0717 - acc: 0.7500\n",
      "Epoch 243/500\n",
      " - 0s - loss: 1.0677 - acc: 0.7500\n",
      "Epoch 244/500\n",
      " - 0s - loss: 1.0636 - acc: 0.7500\n",
      "Epoch 245/500\n",
      " - 0s - loss: 1.0596 - acc: 0.7500\n",
      "Epoch 246/500\n",
      " - 0s - loss: 1.0556 - acc: 0.7500\n",
      "Epoch 247/500\n",
      " - 0s - loss: 1.0517 - acc: 0.7500\n",
      "Epoch 248/500\n",
      " - 0s - loss: 1.0477 - acc: 0.7500\n",
      "Epoch 249/500\n",
      " - 0s - loss: 1.0437 - acc: 0.7500\n",
      "Epoch 250/500\n",
      " - 0s - loss: 1.0398 - acc: 0.7500\n",
      "Epoch 251/500\n",
      " - 0s - loss: 1.0358 - acc: 0.7500\n",
      "Epoch 252/500\n",
      " - 0s - loss: 1.0319 - acc: 0.7500\n",
      "Epoch 253/500\n",
      " - 0s - loss: 1.0280 - acc: 0.7500\n",
      "Epoch 254/500\n",
      " - 0s - loss: 1.0241 - acc: 0.7500\n",
      "Epoch 255/500\n",
      " - 0s - loss: 1.0202 - acc: 0.7500\n",
      "Epoch 256/500\n",
      " - 0s - loss: 1.0163 - acc: 0.7500\n",
      "Epoch 257/500\n",
      " - 0s - loss: 1.0124 - acc: 0.7500\n",
      "Epoch 258/500\n",
      " - 0s - loss: 1.0085 - acc: 0.7500\n",
      "Epoch 259/500\n",
      " - 0s - loss: 1.0047 - acc: 0.7500\n",
      "Epoch 260/500\n",
      " - 0s - loss: 1.0008 - acc: 0.7500\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.9970 - acc: 0.7500\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.9931 - acc: 0.7500\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.9893 - acc: 0.7500\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.9855 - acc: 0.8750\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.9817 - acc: 0.8750\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.9779 - acc: 0.8750\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.9741 - acc: 0.8750\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.9703 - acc: 0.8750\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.9666 - acc: 0.8750\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.9628 - acc: 0.8750\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.9590 - acc: 0.8750\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.9553 - acc: 0.8750\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.9516 - acc: 0.8750\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.9479 - acc: 0.8750\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.9442 - acc: 0.8750\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.9405 - acc: 0.8750\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.9368 - acc: 0.8750\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.9331 - acc: 0.8750\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.9294 - acc: 0.8750\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.9258 - acc: 0.8750\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.9221 - acc: 0.8750\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.9185 - acc: 0.8750\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.9149 - acc: 0.8750\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.9112 - acc: 0.8750\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.9076 - acc: 0.8750\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.9040 - acc: 0.8750\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.9005 - acc: 0.8750\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.8969 - acc: 0.8750\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.8933 - acc: 0.8750\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.8898 - acc: 0.8750\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.8862 - acc: 0.8750\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.8827 - acc: 0.8750\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.8792 - acc: 0.8750\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.8757 - acc: 0.8750\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.8722 - acc: 0.8750\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.8687 - acc: 0.8750\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.8653 - acc: 0.8750\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.8618 - acc: 0.8750\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.8584 - acc: 0.8750\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.8549 - acc: 0.8750\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.8515 - acc: 0.8750\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.8481 - acc: 0.8750\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.8447 - acc: 0.8750\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.8413 - acc: 0.8750\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.8380 - acc: 0.8750\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.8346 - acc: 0.8750\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.8313 - acc: 0.8750\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.8280 - acc: 0.8750\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.8246 - acc: 0.8750\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.8213 - acc: 0.8750\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.8181 - acc: 0.8750\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.8148 - acc: 0.8750\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.8115 - acc: 0.8750\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.8083 - acc: 0.8750\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.8050 - acc: 0.8750\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.8018 - acc: 0.8750\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.7986 - acc: 0.8750\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.7954 - acc: 0.8750\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.7923 - acc: 0.8750\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.7891 - acc: 0.8750\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.7860 - acc: 0.8750\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.7828 - acc: 0.8750\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.7797 - acc: 0.8750\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.7766 - acc: 0.8750\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.7735 - acc: 0.8750\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.7705 - acc: 0.8750\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.7674 - acc: 0.8750\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.7644 - acc: 0.8750\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.7613 - acc: 0.8750\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.7583 - acc: 0.8750\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.7553 - acc: 0.8750\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.7523 - acc: 0.8750\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.7494 - acc: 0.8750\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.7464 - acc: 0.8750\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.7435 - acc: 0.8750\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.7406 - acc: 0.8750\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.7377 - acc: 0.8750\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.7348 - acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/500\n",
      " - 0s - loss: 0.7319 - acc: 0.8750\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.7290 - acc: 0.8750\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.7262 - acc: 0.8750\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.7234 - acc: 0.8750\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.7205 - acc: 0.8750\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.7178 - acc: 0.8750\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.7150 - acc: 0.8750\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.7122 - acc: 0.8750\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.7095 - acc: 0.8750\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.7067 - acc: 0.8750\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.7040 - acc: 0.8750\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.7013 - acc: 0.8750\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.6986 - acc: 0.8750\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.6959 - acc: 0.8750\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.6933 - acc: 0.8750\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.6906 - acc: 0.8750\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.6880 - acc: 0.8750\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.6854 - acc: 0.8750\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.6828 - acc: 0.8750\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.6802 - acc: 0.8750\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.6777 - acc: 0.8750\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.6751 - acc: 0.8750\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.6726 - acc: 0.8750\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.6701 - acc: 0.8750\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.6675 - acc: 0.8750\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.6651 - acc: 0.8750\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.6626 - acc: 0.8750\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.6601 - acc: 0.8750\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.6577 - acc: 0.8750\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.6553 - acc: 0.8750\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.6528 - acc: 0.8750\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.6505 - acc: 0.8750\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.6481 - acc: 0.8750\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.6457 - acc: 0.8750\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.6433 - acc: 0.8750\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.6410 - acc: 0.8750\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.6387 - acc: 0.8750\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.6364 - acc: 0.8750\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.6341 - acc: 0.8750\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.6318 - acc: 0.8750\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.6295 - acc: 0.8750\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.6273 - acc: 0.8750\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.6251 - acc: 0.8750\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.6228 - acc: 0.8750\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.6206 - acc: 0.8750\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.6184 - acc: 0.8750\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.6162 - acc: 0.8750\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.6141 - acc: 0.8750\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.6119 - acc: 0.8750\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.6098 - acc: 0.8750\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.6077 - acc: 0.8750\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.6056 - acc: 0.8750\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.6035 - acc: 0.8750\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.6014 - acc: 0.8750\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.5993 - acc: 0.8750\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.5973 - acc: 0.8750\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.5952 - acc: 0.8750\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.5932 - acc: 0.8750\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.5912 - acc: 0.8750\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.5892 - acc: 0.8750\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.5872 - acc: 0.8750\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.5852 - acc: 0.8750\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.5833 - acc: 0.8750\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.5813 - acc: 0.8750\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.5794 - acc: 0.8750\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.5774 - acc: 0.8750\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.5755 - acc: 0.8750\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.5736 - acc: 0.8750\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.5717 - acc: 0.8750\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.5699 - acc: 0.8750\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.5680 - acc: 0.8750\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.5662 - acc: 0.8750\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.5643 - acc: 0.8750\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.5625 - acc: 0.8750\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.5607 - acc: 0.8750\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.5589 - acc: 0.8750\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.5571 - acc: 0.8750\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.5553 - acc: 0.8750\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.5536 - acc: 0.8750\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.5518 - acc: 0.8750\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.5501 - acc: 0.8750\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.5483 - acc: 0.8750\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.5466 - acc: 0.8750\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.5449 - acc: 0.8750\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.5432 - acc: 0.8750\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.5415 - acc: 0.8750\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.5399 - acc: 0.8750\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.5382 - acc: 0.8750\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.5366 - acc: 0.8750\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.5349 - acc: 0.8750\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.5333 - acc: 0.8750\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.5317 - acc: 0.8750\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.5301 - acc: 0.8750\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.5285 - acc: 0.8750\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.5269 - acc: 0.8750\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.5253 - acc: 0.8750\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.5237 - acc: 0.8750\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.5222 - acc: 0.8750\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.5206 - acc: 0.8750\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.5191 - acc: 0.8750\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.5176 - acc: 0.8750\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.5161 - acc: 0.8750\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.5146 - acc: 0.8750\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.5131 - acc: 0.8750\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.5116 - acc: 0.8750\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.5101 - acc: 0.8750\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.5087 - acc: 0.8750\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.5072 - acc: 0.8750\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.5058 - acc: 0.8750\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.5043 - acc: 0.8750\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.5029 - acc: 0.8750\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.5015 - acc: 0.8750\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.5001 - acc: 0.8750\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.4987 - acc: 0.8750\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.4973 - acc: 0.8750\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.4959 - acc: 0.8750\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.4945 - acc: 0.8750\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.4932 - acc: 0.8750\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.4918 - acc: 0.8750\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.4905 - acc: 0.8750\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.4891 - acc: 0.8750\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.4878 - acc: 0.8750\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.4865 - acc: 0.8750\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.4852 - acc: 0.8750\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.4839 - acc: 0.8750\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.4826 - acc: 0.8750\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.4813 - acc: 0.8750\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.4800 - acc: 0.8750\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.4788 - acc: 0.8750\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.4775 - acc: 0.8750\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.4763 - acc: 0.8750\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.4750 - acc: 0.8750\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.4738 - acc: 0.8750\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.4726 - acc: 0.8750\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.4713 - acc: 0.8750\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.4701 - acc: 0.8750\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.4689 - acc: 0.8750\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.4677 - acc: 0.8750\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.4665 - acc: 0.8750\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.4654 - acc: 0.8750\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.4642 - acc: 0.8750\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.4630 - acc: 0.8750\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.4619 - acc: 0.8750\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.4607 - acc: 0.8750\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.4596 - acc: 0.8750\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.4584 - acc: 0.8750\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.4573 - acc: 0.8750\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.4562 - acc: 0.8750\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.4551 - acc: 0.8750\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.4540 - acc: 0.8750\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.4528 - acc: 0.8750\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.4518 - acc: 0.8750\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.4507 - acc: 0.8750\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.4496 - acc: 0.8750\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.4485 - acc: 0.8750\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.4474 - acc: 0.8750\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.4464 - acc: 0.8750\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.4453 - acc: 0.8750\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.4443 - acc: 0.8750\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.4432 - acc: 0.8750\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.4422 - acc: 0.8750\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.4412 - acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222824deb00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs = 500, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00256979, 0.8274486 , 0.00151399, 0.01444408, 0.01967066,\n",
       "        0.04317044, 0.0172597 , 0.03563479, 0.03828797],\n",
       "       [0.00679117, 0.04484701, 0.00631687, 0.43639392, 0.08080025,\n",
       "        0.00412814, 0.0122248 , 0.36779165, 0.04070619],\n",
       "       [0.00502335, 0.02052069, 0.0113963 , 0.05111485, 0.662641  ,\n",
       "        0.00238852, 0.14927013, 0.09376051, 0.0038847 ],\n",
       "       [0.01627569, 0.07024859, 0.01190672, 0.00117477, 0.00112039,\n",
       "        0.80329955, 0.02813037, 0.00474252, 0.0631015 ],\n",
       "       [0.02623983, 0.01352234, 0.02335316, 0.00935724, 0.1475742 ,\n",
       "        0.05063564, 0.69703424, 0.02882266, 0.0034607 ],\n",
       "       [0.00255992, 0.82756495, 0.00151065, 0.01461028, 0.01951721,\n",
       "        0.04271834, 0.01692571, 0.03583818, 0.0387547 ],\n",
       "       [0.00679117, 0.04484701, 0.00631687, 0.43639392, 0.08080025,\n",
       "        0.00412814, 0.0122248 , 0.36779165, 0.04070619],\n",
       "       [0.0208605 , 0.10249052, 0.02171944, 0.04031161, 0.00255108,\n",
       "        0.04559111, 0.00275624, 0.0387997 , 0.7249198 ]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('점심', 1), ('나랑', 2), ('먹으러', 3), ('갈래', 4), ('메뉴는', 5), ('햄버거', 6), ('메뉴', 7), ('좋지', 8)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index.items() # key와 value의 값을 쌍으로 튜플로 묶은 값을 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 단어를 출력하는 함수를 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, t, current_word) :\n",
    "    encoded = t.texts_to_sequences([current_word])[0]\n",
    "    encoded = np.array(encoded)\n",
    "    result = model.predict_classes(encoded, verbose=0)\n",
    "    for word, index in t.word_index.items() :\n",
    "        if index == result :\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'갈래'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, t, '먹으러')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방금 실습했던 함수를 for문과 조합하여 반복하도록 만들어 문장을 생성하는 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n) :\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "    for _ in range(n) : #n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0]\n",
    "        encoded = np.array(encoded)\n",
    "        result = model.predict_classes(encoded, verbose = 0)\n",
    "        for word, index in t.word_index.items() :\n",
    "            if index == result :\n",
    "                break\n",
    "        current_word = word\n",
    "        sentence = sentence + ' ' + word\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'점심 먹으러 갈래 메뉴는 햄버거 점심 먹으러 갈래 메뉴는 햄버거'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, '점심', 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞선 모델은 훈련 데이터에 '점심' 다음에 '먹으러'와 '메뉴'라는 단어가 한 번씩 나옴에 따라 어떤 단어를 선택할지 헷갈리는 모습을 보여줌\n",
    "- 다음 단어 등장 횟수가 같다고 해서 헷갈린다는 것은, 해당 모델이 문맥을 전혀 반영하지 못하는 모델이라는 것을 의미\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> 대안은 모델이 문맥을 학습할 수 있도록 앞의 단어들도 함께 학습시키는 것. \n",
    "- 즉, 이전 모델처럼 현재 단어 + 다음 단어의 쌍(pair)을 X와 y로 훈련시키는 것이 아니라, 앞에 등장한 모든 단어의 시퀀스를 X로 학습시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화와 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "encoded = t.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 4, 5, 6, 1, 7, 8, 1, 9, 10, 1, 11]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'말이': 1,\n",
       " '경마장에': 2,\n",
       " '있는': 3,\n",
       " '뛰고': 4,\n",
       " '있다': 5,\n",
       " '그의': 6,\n",
       " '법이다': 7,\n",
       " '가는': 8,\n",
       " '고와야': 9,\n",
       " '오는': 10,\n",
       " '곱다': 11}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 11\n"
     ]
    }
   ],
   "source": [
    "#훈련 데이터 만들기\n",
    "sequences = list()\n",
    "for line in text.split('\\n') :\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)) :\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "print('훈련 데이터의 개수 : %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 훈련 데이터에 대해 맨 우측에 있는 단어에 대해서만 y로 분리하면 X와 y의 쌍이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X와 y를 분리하기 전 모든 데이터의 길이를 맞춰야 함.\n",
    "max(len(i) for i in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 데이터에 대해 길이를 6으로 맞춰줌\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "sequences = pad_sequences(sequences, maxlen=6, padding='pre')\n",
    "#모든 데이터에 대해 0을 추가해서 길이를 맞춰줌\n",
    "#maxlen : 데이터를 맞춰줄 길이\n",
    "#padding='pre' : 길이가 6보다 짧은 데이터의 앞을 0으로 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  2,  3,  1],\n",
       "       [ 0,  2,  3,  1,  4],\n",
       "       [ 0,  0,  0,  0,  6],\n",
       "       [ 0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  0,  8],\n",
       "       [ 0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  8,  1,  9],\n",
       "       [ 0,  8,  1,  9, 10],\n",
       "       [ 8,  1,  9, 10,  1]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4,  5,  1,  7,  1,  9, 10,  1, 11])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩 수행 -> y에 대해서\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 1s - loss: 2.4511 - acc: 0.2727\n",
      "Epoch 2/200\n",
      " - 0s - loss: 2.4373 - acc: 0.2727\n",
      "Epoch 3/200\n",
      " - 0s - loss: 2.4231 - acc: 0.2727\n",
      "Epoch 4/200\n",
      " - 0s - loss: 2.4084 - acc: 0.3636\n",
      "Epoch 5/200\n",
      " - 0s - loss: 2.3930 - acc: 0.3636\n",
      "Epoch 6/200\n",
      " - 0s - loss: 2.3771 - acc: 0.3636\n",
      "Epoch 7/200\n",
      " - 0s - loss: 2.3605 - acc: 0.3636\n",
      "Epoch 8/200\n",
      " - 0s - loss: 2.3431 - acc: 0.3636\n",
      "Epoch 9/200\n",
      " - 0s - loss: 2.3250 - acc: 0.3636\n",
      "Epoch 10/200\n",
      " - 0s - loss: 2.3061 - acc: 0.3636\n",
      "Epoch 11/200\n",
      " - 0s - loss: 2.2863 - acc: 0.3636\n",
      "Epoch 12/200\n",
      " - 0s - loss: 2.2657 - acc: 0.3636\n",
      "Epoch 13/200\n",
      " - 0s - loss: 2.2444 - acc: 0.3636\n",
      "Epoch 14/200\n",
      " - 0s - loss: 2.2223 - acc: 0.3636\n",
      "Epoch 15/200\n",
      " - 0s - loss: 2.1995 - acc: 0.3636\n",
      "Epoch 16/200\n",
      " - 0s - loss: 2.1762 - acc: 0.3636\n",
      "Epoch 17/200\n",
      " - 0s - loss: 2.1526 - acc: 0.3636\n",
      "Epoch 18/200\n",
      " - 0s - loss: 2.1287 - acc: 0.3636\n",
      "Epoch 19/200\n",
      " - 0s - loss: 2.1050 - acc: 0.3636\n",
      "Epoch 20/200\n",
      " - 0s - loss: 2.0815 - acc: 0.3636\n",
      "Epoch 21/200\n",
      " - 0s - loss: 2.0587 - acc: 0.3636\n",
      "Epoch 22/200\n",
      " - 0s - loss: 2.0368 - acc: 0.3636\n",
      "Epoch 23/200\n",
      " - 0s - loss: 2.0161 - acc: 0.3636\n",
      "Epoch 24/200\n",
      " - 0s - loss: 1.9968 - acc: 0.3636\n",
      "Epoch 25/200\n",
      " - 0s - loss: 1.9789 - acc: 0.3636\n",
      "Epoch 26/200\n",
      " - 0s - loss: 1.9625 - acc: 0.3636\n",
      "Epoch 27/200\n",
      " - 0s - loss: 1.9475 - acc: 0.3636\n",
      "Epoch 28/200\n",
      " - 0s - loss: 1.9336 - acc: 0.3636\n",
      "Epoch 29/200\n",
      " - 0s - loss: 1.9205 - acc: 0.3636\n",
      "Epoch 30/200\n",
      " - 0s - loss: 1.9078 - acc: 0.3636\n",
      "Epoch 31/200\n",
      " - 0s - loss: 1.8951 - acc: 0.3636\n",
      "Epoch 32/200\n",
      " - 0s - loss: 1.8823 - acc: 0.3636\n",
      "Epoch 33/200\n",
      " - 0s - loss: 1.8690 - acc: 0.3636\n",
      "Epoch 34/200\n",
      " - 0s - loss: 1.8552 - acc: 0.3636\n",
      "Epoch 35/200\n",
      " - 0s - loss: 1.8409 - acc: 0.3636\n",
      "Epoch 36/200\n",
      " - 0s - loss: 1.8262 - acc: 0.3636\n",
      "Epoch 37/200\n",
      " - 0s - loss: 1.8112 - acc: 0.3636\n",
      "Epoch 38/200\n",
      " - 0s - loss: 1.7959 - acc: 0.3636\n",
      "Epoch 39/200\n",
      " - 0s - loss: 1.7804 - acc: 0.3636\n",
      "Epoch 40/200\n",
      " - 0s - loss: 1.7649 - acc: 0.3636\n",
      "Epoch 41/200\n",
      " - 0s - loss: 1.7494 - acc: 0.3636\n",
      "Epoch 42/200\n",
      " - 0s - loss: 1.7338 - acc: 0.3636\n",
      "Epoch 43/200\n",
      " - 0s - loss: 1.7182 - acc: 0.3636\n",
      "Epoch 44/200\n",
      " - 0s - loss: 1.7023 - acc: 0.3636\n",
      "Epoch 45/200\n",
      " - 0s - loss: 1.6861 - acc: 0.4545\n",
      "Epoch 46/200\n",
      " - 0s - loss: 1.6696 - acc: 0.4545\n",
      "Epoch 47/200\n",
      " - 0s - loss: 1.6526 - acc: 0.4545\n",
      "Epoch 48/200\n",
      " - 0s - loss: 1.6351 - acc: 0.4545\n",
      "Epoch 49/200\n",
      " - 0s - loss: 1.6169 - acc: 0.4545\n",
      "Epoch 50/200\n",
      " - 0s - loss: 1.5982 - acc: 0.4545\n",
      "Epoch 51/200\n",
      " - 0s - loss: 1.5790 - acc: 0.4545\n",
      "Epoch 52/200\n",
      " - 0s - loss: 1.5592 - acc: 0.4545\n",
      "Epoch 53/200\n",
      " - 0s - loss: 1.5389 - acc: 0.4545\n",
      "Epoch 54/200\n",
      " - 0s - loss: 1.5181 - acc: 0.4545\n",
      "Epoch 55/200\n",
      " - 0s - loss: 1.4968 - acc: 0.5455\n",
      "Epoch 56/200\n",
      " - 0s - loss: 1.4752 - acc: 0.5455\n",
      "Epoch 57/200\n",
      " - 0s - loss: 1.4531 - acc: 0.6364\n",
      "Epoch 58/200\n",
      " - 0s - loss: 1.4307 - acc: 0.6364\n",
      "Epoch 59/200\n",
      " - 0s - loss: 1.4078 - acc: 0.6364\n",
      "Epoch 60/200\n",
      " - 0s - loss: 1.3846 - acc: 0.6364\n",
      "Epoch 61/200\n",
      " - 0s - loss: 1.3611 - acc: 0.6364\n",
      "Epoch 62/200\n",
      " - 0s - loss: 1.3372 - acc: 0.6364\n",
      "Epoch 63/200\n",
      " - 0s - loss: 1.3132 - acc: 0.7273\n",
      "Epoch 64/200\n",
      " - 0s - loss: 1.2890 - acc: 0.7273\n",
      "Epoch 65/200\n",
      " - 0s - loss: 1.2646 - acc: 0.7273\n",
      "Epoch 66/200\n",
      " - 0s - loss: 1.2403 - acc: 0.7273\n",
      "Epoch 67/200\n",
      " - 0s - loss: 1.2161 - acc: 0.7273\n",
      "Epoch 68/200\n",
      " - 0s - loss: 1.1920 - acc: 0.7273\n",
      "Epoch 69/200\n",
      " - 0s - loss: 1.1681 - acc: 0.7273\n",
      "Epoch 70/200\n",
      " - 0s - loss: 1.1445 - acc: 0.7273\n",
      "Epoch 71/200\n",
      " - 0s - loss: 1.1211 - acc: 0.7273\n",
      "Epoch 72/200\n",
      " - 0s - loss: 1.0981 - acc: 0.7273\n",
      "Epoch 73/200\n",
      " - 0s - loss: 1.0754 - acc: 0.7273\n",
      "Epoch 74/200\n",
      " - 0s - loss: 1.0532 - acc: 0.7273\n",
      "Epoch 75/200\n",
      " - 0s - loss: 1.0314 - acc: 0.7273\n",
      "Epoch 76/200\n",
      " - 0s - loss: 1.0100 - acc: 0.7273\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.9891 - acc: 0.7273\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.9688 - acc: 0.7273\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.9489 - acc: 0.7273\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.9296 - acc: 0.7273\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.9109 - acc: 0.7273\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.8926 - acc: 0.7273\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.8749 - acc: 0.7273\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.8577 - acc: 0.7273\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.8410 - acc: 0.7273\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.8248 - acc: 0.7273\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.8090 - acc: 0.7273\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.7938 - acc: 0.7273\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.7789 - acc: 0.7273\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.7645 - acc: 0.7273\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.7506 - acc: 0.7273\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.7370 - acc: 0.7273\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.7238 - acc: 0.7273\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.7109 - acc: 0.7273\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.6984 - acc: 0.7273\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.6862 - acc: 0.7273\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.6743 - acc: 0.7273\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.6628 - acc: 0.7273\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.6515 - acc: 0.7273\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6404 - acc: 0.8182\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6297 - acc: 0.8182\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6192 - acc: 0.8182\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6089 - acc: 0.8182\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.5988 - acc: 0.8182\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.5890 - acc: 0.8182\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.5793 - acc: 0.8182\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.5698 - acc: 0.8182\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.5605 - acc: 0.8182\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.5514 - acc: 0.8182\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.5424 - acc: 0.8182\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.5336 - acc: 0.8182\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.5250 - acc: 0.8182\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.5164 - acc: 0.8182\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.5080 - acc: 0.9091\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.4997 - acc: 0.9091\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.4916 - acc: 0.9091\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.4835 - acc: 0.9091\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.4756 - acc: 0.9091\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.4678 - acc: 0.9091\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.4601 - acc: 0.9091\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.4524 - acc: 0.9091\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.4449 - acc: 0.9091\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.4375 - acc: 0.9091\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.4301 - acc: 0.9091\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.4229 - acc: 0.9091\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.4157 - acc: 0.9091\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.4086 - acc: 0.9091\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.4017 - acc: 0.9091\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.3948 - acc: 0.9091\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.3880 - acc: 0.9091\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.3813 - acc: 0.9091\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.3746 - acc: 0.9091\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.3681 - acc: 0.9091\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.3616 - acc: 0.9091\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.3553 - acc: 0.9091\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.3490 - acc: 0.9091\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.3428 - acc: 0.9091\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.3367 - acc: 0.9091\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.3307 - acc: 0.9091\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.3248 - acc: 0.9091\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.3190 - acc: 0.9091\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.3132 - acc: 0.9091\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.3076 - acc: 0.9091\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.3021 - acc: 0.9091\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.2966 - acc: 0.9091\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.2912 - acc: 0.9091\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.2860 - acc: 0.9091\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.2808 - acc: 0.9091\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.2757 - acc: 0.9091\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.2707 - acc: 0.9091\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.2658 - acc: 1.0000\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.2610 - acc: 1.0000\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.2562 - acc: 1.0000\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.2516 - acc: 1.0000\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.2470 - acc: 1.0000\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.2426 - acc: 1.0000\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.2382 - acc: 1.0000\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.2339 - acc: 1.0000\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.2297 - acc: 1.0000\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.2256 - acc: 1.0000\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.2215 - acc: 1.0000\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.2176 - acc: 1.0000\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.2137 - acc: 1.0000\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.2099 - acc: 1.0000\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.2061 - acc: 1.0000\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.2025 - acc: 1.0000\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.1989 - acc: 1.0000\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.1954 - acc: 1.0000\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.1920 - acc: 1.0000\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.1886 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      " - 0s - loss: 0.1853 - acc: 1.0000\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.1821 - acc: 1.0000\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.1789 - acc: 1.0000\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.1758 - acc: 1.0000\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.1728 - acc: 1.0000\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.1698 - acc: 1.0000\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.1669 - acc: 1.0000\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.1640 - acc: 1.0000\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.1612 - acc: 1.0000\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.1585 - acc: 1.0000\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.1558 - acc: 1.0000\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.1532 - acc: 1.0000\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.1506 - acc: 1.0000\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.1481 - acc: 1.0000\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.1457 - acc: 1.0000\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.1432 - acc: 1.0000\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.1409 - acc: 1.0000\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.1385 - acc: 1.0000\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.1363 - acc: 1.0000\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.1340 - acc: 1.0000\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.1319 - acc: 1.0000\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.1297 - acc: 1.0000\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.1276 - acc: 1.0000\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.1256 - acc: 1.0000\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.1236 - acc: 1.0000\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.1216 - acc: 1.0000\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.1197 - acc: 1.0000\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.1178 - acc: 1.0000\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.1159 - acc: 1.0000\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.1141 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22286ac59b0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Embedding, Dense, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length = 5)) # y를 제거했으므로 의 길이는 5\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocab_size, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs = 200, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델이 정확하게 예측하고 있는지 문장을 생성하는 함수를 만들어 실제로 출력해보기기\n",
    "\n",
    "def sentence_generation(model, t, current_word, n) :\n",
    "    init_word = current_word\n",
    "    sentence= ''\n",
    "    for _ in range(n) :\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') # 데이터에 대한 패딩\n",
    "        result = model.predict_classes(encoded, verbose = 0)\n",
    "        for word, index in t.word_index.items() :\n",
    "            if index == result :\n",
    "                break\n",
    "        current_word = current_word + ' ' + word\n",
    "        sentence = sentence + ' ' + word\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'경마장에 있는 말이 뛰고 있다'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, '경마장에 있는', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가는 말이 고와야 오는 말이 곱다'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, '가는 말이', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그의 말이 법이다'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, '그의', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'법이다 말이 말이 오는 말이 곱다 오는 말이 곱다 오는 말이'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, '법이다', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문장의 단어 갯수 이상의 숫자를 주면, '있다', '곱다', '법이다' 이후 단어가 무엇인지 배울 수 없으므로 임의로 예측을 하기 시작함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cf\n",
    "t.texts_to_sequences(['경마장에 있는'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sequences([t.texts_to_sequences(['경마장에 있는'])[0]], maxlen=5, padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 나랑 점심 먹으러 갈래 메뉴는 햄버거 점심 메뉴 좋지 문맥 고려 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"나랑 점심 먹으러 갈래 메뉴는 햄버거 점심 메뉴 좋지\"\n",
    "t2=Tokenizer()\n",
    "t2.fit_on_texts([text]) # cf 리스트 형태로 넣어주지 않으면 한 글자씩 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'점심': 1, '나랑': 2, '먹으러': 3, '갈래': 4, '메뉴는': 5, '햄버거': 6, '메뉴': 7, '좋지': 8}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size2 = len(t2.word_index) + 1 # 1부터 들어가므로 +1 해주기\n",
    "t2.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = t2.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3, 4, 5, 6, 1, 7, 8]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=[]\n",
    "for i in range(1, len(encoded)) :\n",
    "    sequences.append(encoded[i-1:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1], [1, 3], [3, 4], [4, 5], [5, 6], [6, 1], [1, 7], [7, 8]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = zip(*sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y 원핫인코딩\n",
    "y = to_categorical(y, size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 1s - loss: 2.1925 - acc: 0.3750\n",
      "Epoch 2/200\n",
      " - 0s - loss: 2.1886 - acc: 0.3750\n",
      "Epoch 3/200\n",
      " - 0s - loss: 2.1846 - acc: 0.3750\n",
      "Epoch 4/200\n",
      " - 0s - loss: 2.1806 - acc: 0.3750\n",
      "Epoch 5/200\n",
      " - 0s - loss: 2.1766 - acc: 0.3750\n",
      "Epoch 6/200\n",
      " - 0s - loss: 2.1727 - acc: 0.3750\n",
      "Epoch 7/200\n",
      " - 0s - loss: 2.1687 - acc: 0.3750\n",
      "Epoch 8/200\n",
      " - 0s - loss: 2.1648 - acc: 0.3750\n",
      "Epoch 9/200\n",
      " - 0s - loss: 2.1608 - acc: 0.3750\n",
      "Epoch 10/200\n",
      " - 0s - loss: 2.1568 - acc: 0.3750\n",
      "Epoch 11/200\n",
      " - 0s - loss: 2.1528 - acc: 0.3750\n",
      "Epoch 12/200\n",
      " - 0s - loss: 2.1488 - acc: 0.3750\n",
      "Epoch 13/200\n",
      " - 0s - loss: 2.1448 - acc: 0.3750\n",
      "Epoch 14/200\n",
      " - 0s - loss: 2.1408 - acc: 0.3750\n",
      "Epoch 15/200\n",
      " - 0s - loss: 2.1368 - acc: 0.3750\n",
      "Epoch 16/200\n",
      " - 0s - loss: 2.1327 - acc: 0.3750\n",
      "Epoch 17/200\n",
      " - 0s - loss: 2.1287 - acc: 0.3750\n",
      "Epoch 18/200\n",
      " - 0s - loss: 2.1246 - acc: 0.3750\n",
      "Epoch 19/200\n",
      " - 0s - loss: 2.1205 - acc: 0.3750\n",
      "Epoch 20/200\n",
      " - 0s - loss: 2.1163 - acc: 0.3750\n",
      "Epoch 21/200\n",
      " - 0s - loss: 2.1122 - acc: 0.5000\n",
      "Epoch 22/200\n",
      " - 0s - loss: 2.1080 - acc: 0.5000\n",
      "Epoch 23/200\n",
      " - 0s - loss: 2.1037 - acc: 0.5000\n",
      "Epoch 24/200\n",
      " - 0s - loss: 2.0995 - acc: 0.5000\n",
      "Epoch 25/200\n",
      " - 0s - loss: 2.0952 - acc: 0.5000\n",
      "Epoch 26/200\n",
      " - 0s - loss: 2.0909 - acc: 0.5000\n",
      "Epoch 27/200\n",
      " - 0s - loss: 2.0865 - acc: 0.5000\n",
      "Epoch 28/200\n",
      " - 0s - loss: 2.0821 - acc: 0.5000\n",
      "Epoch 29/200\n",
      " - 0s - loss: 2.0777 - acc: 0.5000\n",
      "Epoch 30/200\n",
      " - 0s - loss: 2.0732 - acc: 0.5000\n",
      "Epoch 31/200\n",
      " - 0s - loss: 2.0687 - acc: 0.5000\n",
      "Epoch 32/200\n",
      " - 0s - loss: 2.0641 - acc: 0.5000\n",
      "Epoch 33/200\n",
      " - 0s - loss: 2.0595 - acc: 0.5000\n",
      "Epoch 34/200\n",
      " - 0s - loss: 2.0549 - acc: 0.5000\n",
      "Epoch 35/200\n",
      " - 0s - loss: 2.0501 - acc: 0.5000\n",
      "Epoch 36/200\n",
      " - 0s - loss: 2.0454 - acc: 0.5000\n",
      "Epoch 37/200\n",
      " - 0s - loss: 2.0406 - acc: 0.5000\n",
      "Epoch 38/200\n",
      " - 0s - loss: 2.0357 - acc: 0.5000\n",
      "Epoch 39/200\n",
      " - 0s - loss: 2.0308 - acc: 0.5000\n",
      "Epoch 40/200\n",
      " - 0s - loss: 2.0259 - acc: 0.5000\n",
      "Epoch 41/200\n",
      " - 0s - loss: 2.0209 - acc: 0.5000\n",
      "Epoch 42/200\n",
      " - 0s - loss: 2.0158 - acc: 0.5000\n",
      "Epoch 43/200\n",
      " - 0s - loss: 2.0107 - acc: 0.5000\n",
      "Epoch 44/200\n",
      " - 0s - loss: 2.0055 - acc: 0.5000\n",
      "Epoch 45/200\n",
      " - 0s - loss: 2.0003 - acc: 0.5000\n",
      "Epoch 46/200\n",
      " - 0s - loss: 1.9950 - acc: 0.5000\n",
      "Epoch 47/200\n",
      " - 0s - loss: 1.9896 - acc: 0.5000\n",
      "Epoch 48/200\n",
      " - 0s - loss: 1.9842 - acc: 0.5000\n",
      "Epoch 49/200\n",
      " - 0s - loss: 1.9788 - acc: 0.5000\n",
      "Epoch 50/200\n",
      " - 0s - loss: 1.9733 - acc: 0.5000\n",
      "Epoch 51/200\n",
      " - 0s - loss: 1.9677 - acc: 0.5000\n",
      "Epoch 52/200\n",
      " - 0s - loss: 1.9620 - acc: 0.5000\n",
      "Epoch 53/200\n",
      " - 0s - loss: 1.9563 - acc: 0.5000\n",
      "Epoch 54/200\n",
      " - 0s - loss: 1.9506 - acc: 0.5000\n",
      "Epoch 55/200\n",
      " - 0s - loss: 1.9448 - acc: 0.5000\n",
      "Epoch 56/200\n",
      " - 0s - loss: 1.9389 - acc: 0.6250\n",
      "Epoch 57/200\n",
      " - 0s - loss: 1.9329 - acc: 0.6250\n",
      "Epoch 58/200\n",
      " - 0s - loss: 1.9269 - acc: 0.6250\n",
      "Epoch 59/200\n",
      " - 0s - loss: 1.9209 - acc: 0.6250\n",
      "Epoch 60/200\n",
      " - 0s - loss: 1.9147 - acc: 0.6250\n",
      "Epoch 61/200\n",
      " - 0s - loss: 1.9085 - acc: 0.6250\n",
      "Epoch 62/200\n",
      " - 0s - loss: 1.9023 - acc: 0.6250\n",
      "Epoch 63/200\n",
      " - 0s - loss: 1.8960 - acc: 0.7500\n",
      "Epoch 64/200\n",
      " - 0s - loss: 1.8896 - acc: 0.7500\n",
      "Epoch 65/200\n",
      " - 0s - loss: 1.8832 - acc: 0.7500\n",
      "Epoch 66/200\n",
      " - 0s - loss: 1.8766 - acc: 0.7500\n",
      "Epoch 67/200\n",
      " - 0s - loss: 1.8701 - acc: 0.7500\n",
      "Epoch 68/200\n",
      " - 0s - loss: 1.8635 - acc: 0.7500\n",
      "Epoch 69/200\n",
      " - 0s - loss: 1.8568 - acc: 0.7500\n",
      "Epoch 70/200\n",
      " - 0s - loss: 1.8500 - acc: 0.7500\n",
      "Epoch 71/200\n",
      " - 0s - loss: 1.8432 - acc: 0.7500\n",
      "Epoch 72/200\n",
      " - 0s - loss: 1.8363 - acc: 0.7500\n",
      "Epoch 73/200\n",
      " - 0s - loss: 1.8294 - acc: 0.7500\n",
      "Epoch 74/200\n",
      " - 0s - loss: 1.8224 - acc: 0.7500\n",
      "Epoch 75/200\n",
      " - 0s - loss: 1.8154 - acc: 0.7500\n",
      "Epoch 76/200\n",
      " - 0s - loss: 1.8082 - acc: 0.7500\n",
      "Epoch 77/200\n",
      " - 0s - loss: 1.8011 - acc: 0.7500\n",
      "Epoch 78/200\n",
      " - 0s - loss: 1.7938 - acc: 0.7500\n",
      "Epoch 79/200\n",
      " - 0s - loss: 1.7865 - acc: 0.7500\n",
      "Epoch 80/200\n",
      " - 0s - loss: 1.7792 - acc: 0.7500\n",
      "Epoch 81/200\n",
      " - 0s - loss: 1.7718 - acc: 0.7500\n",
      "Epoch 82/200\n",
      " - 0s - loss: 1.7643 - acc: 0.7500\n",
      "Epoch 83/200\n",
      " - 0s - loss: 1.7568 - acc: 0.7500\n",
      "Epoch 84/200\n",
      " - 0s - loss: 1.7493 - acc: 0.7500\n",
      "Epoch 85/200\n",
      " - 0s - loss: 1.7416 - acc: 0.7500\n",
      "Epoch 86/200\n",
      " - 0s - loss: 1.7340 - acc: 0.7500\n",
      "Epoch 87/200\n",
      " - 0s - loss: 1.7262 - acc: 0.7500\n",
      "Epoch 88/200\n",
      " - 0s - loss: 1.7184 - acc: 0.7500\n",
      "Epoch 89/200\n",
      " - 0s - loss: 1.7106 - acc: 0.7500\n",
      "Epoch 90/200\n",
      " - 0s - loss: 1.7027 - acc: 0.7500\n",
      "Epoch 91/200\n",
      " - 0s - loss: 1.6948 - acc: 0.7500\n",
      "Epoch 92/200\n",
      " - 0s - loss: 1.6868 - acc: 0.7500\n",
      "Epoch 93/200\n",
      " - 0s - loss: 1.6788 - acc: 0.7500\n",
      "Epoch 94/200\n",
      " - 0s - loss: 1.6707 - acc: 0.7500\n",
      "Epoch 95/200\n",
      " - 0s - loss: 1.6626 - acc: 0.7500\n",
      "Epoch 96/200\n",
      " - 0s - loss: 1.6544 - acc: 0.7500\n",
      "Epoch 97/200\n",
      " - 0s - loss: 1.6462 - acc: 0.7500\n",
      "Epoch 98/200\n",
      " - 0s - loss: 1.6380 - acc: 0.7500\n",
      "Epoch 99/200\n",
      " - 0s - loss: 1.6297 - acc: 0.7500\n",
      "Epoch 100/200\n",
      " - 0s - loss: 1.6214 - acc: 0.7500\n",
      "Epoch 101/200\n",
      " - 0s - loss: 1.6130 - acc: 0.7500\n",
      "Epoch 102/200\n",
      " - 0s - loss: 1.6046 - acc: 0.7500\n",
      "Epoch 103/200\n",
      " - 0s - loss: 1.5961 - acc: 0.7500\n",
      "Epoch 104/200\n",
      " - 0s - loss: 1.5876 - acc: 0.7500\n",
      "Epoch 105/200\n",
      " - 0s - loss: 1.5791 - acc: 0.7500\n",
      "Epoch 106/200\n",
      " - 0s - loss: 1.5706 - acc: 0.7500\n",
      "Epoch 107/200\n",
      " - 0s - loss: 1.5620 - acc: 0.7500\n",
      "Epoch 108/200\n",
      " - 0s - loss: 1.5534 - acc: 0.7500\n",
      "Epoch 109/200\n",
      " - 0s - loss: 1.5448 - acc: 0.7500\n",
      "Epoch 110/200\n",
      " - 0s - loss: 1.5361 - acc: 0.7500\n",
      "Epoch 111/200\n",
      " - 0s - loss: 1.5274 - acc: 0.7500\n",
      "Epoch 112/200\n",
      " - 0s - loss: 1.5187 - acc: 0.7500\n",
      "Epoch 113/200\n",
      " - 0s - loss: 1.5099 - acc: 0.7500\n",
      "Epoch 114/200\n",
      " - 0s - loss: 1.5011 - acc: 0.7500\n",
      "Epoch 115/200\n",
      " - 0s - loss: 1.4923 - acc: 0.7500\n",
      "Epoch 116/200\n",
      " - 0s - loss: 1.4835 - acc: 0.7500\n",
      "Epoch 117/200\n",
      " - 0s - loss: 1.4747 - acc: 0.7500\n",
      "Epoch 118/200\n",
      " - 0s - loss: 1.4658 - acc: 0.7500\n",
      "Epoch 119/200\n",
      " - 0s - loss: 1.4570 - acc: 0.7500\n",
      "Epoch 120/200\n",
      " - 0s - loss: 1.4481 - acc: 0.7500\n",
      "Epoch 121/200\n",
      " - 0s - loss: 1.4392 - acc: 0.7500\n",
      "Epoch 122/200\n",
      " - 0s - loss: 1.4303 - acc: 0.7500\n",
      "Epoch 123/200\n",
      " - 0s - loss: 1.4214 - acc: 0.7500\n",
      "Epoch 124/200\n",
      " - 0s - loss: 1.4124 - acc: 0.7500\n",
      "Epoch 125/200\n",
      " - 0s - loss: 1.4035 - acc: 0.7500\n",
      "Epoch 126/200\n",
      " - 0s - loss: 1.3945 - acc: 0.7500\n",
      "Epoch 127/200\n",
      " - 0s - loss: 1.3856 - acc: 0.7500\n",
      "Epoch 128/200\n",
      " - 0s - loss: 1.3766 - acc: 0.7500\n",
      "Epoch 129/200\n",
      " - 0s - loss: 1.3676 - acc: 0.7500\n",
      "Epoch 130/200\n",
      " - 0s - loss: 1.3587 - acc: 0.7500\n",
      "Epoch 131/200\n",
      " - 0s - loss: 1.3497 - acc: 0.8750\n",
      "Epoch 132/200\n",
      " - 0s - loss: 1.3407 - acc: 0.8750\n",
      "Epoch 133/200\n",
      " - 0s - loss: 1.3317 - acc: 0.8750\n",
      "Epoch 134/200\n",
      " - 0s - loss: 1.3228 - acc: 0.8750\n",
      "Epoch 135/200\n",
      " - 0s - loss: 1.3138 - acc: 0.8750\n",
      "Epoch 136/200\n",
      " - 0s - loss: 1.3049 - acc: 0.8750\n",
      "Epoch 137/200\n",
      " - 0s - loss: 1.2959 - acc: 0.8750\n",
      "Epoch 138/200\n",
      " - 0s - loss: 1.2870 - acc: 0.8750\n",
      "Epoch 139/200\n",
      " - 0s - loss: 1.2781 - acc: 0.8750\n",
      "Epoch 140/200\n",
      " - 0s - loss: 1.2691 - acc: 0.8750\n",
      "Epoch 141/200\n",
      " - 0s - loss: 1.2602 - acc: 0.8750\n",
      "Epoch 142/200\n",
      " - 0s - loss: 1.2513 - acc: 0.8750\n",
      "Epoch 143/200\n",
      " - 0s - loss: 1.2425 - acc: 0.8750\n",
      "Epoch 144/200\n",
      " - 0s - loss: 1.2336 - acc: 0.8750\n",
      "Epoch 145/200\n",
      " - 0s - loss: 1.2248 - acc: 0.8750\n",
      "Epoch 146/200\n",
      " - 0s - loss: 1.2159 - acc: 0.8750\n",
      "Epoch 147/200\n",
      " - 0s - loss: 1.2071 - acc: 0.8750\n",
      "Epoch 148/200\n",
      " - 0s - loss: 1.1984 - acc: 0.8750\n",
      "Epoch 149/200\n",
      " - 0s - loss: 1.1896 - acc: 0.8750\n",
      "Epoch 150/200\n",
      " - 0s - loss: 1.1809 - acc: 0.8750\n",
      "Epoch 151/200\n",
      " - 0s - loss: 1.1722 - acc: 0.8750\n",
      "Epoch 152/200\n",
      " - 0s - loss: 1.1635 - acc: 0.8750\n",
      "Epoch 153/200\n",
      " - 0s - loss: 1.1548 - acc: 0.8750\n",
      "Epoch 154/200\n",
      " - 0s - loss: 1.1462 - acc: 0.8750\n",
      "Epoch 155/200\n",
      " - 0s - loss: 1.1376 - acc: 0.8750\n",
      "Epoch 156/200\n",
      " - 0s - loss: 1.1290 - acc: 0.8750\n",
      "Epoch 157/200\n",
      " - 0s - loss: 1.1205 - acc: 0.8750\n",
      "Epoch 158/200\n",
      " - 0s - loss: 1.1120 - acc: 0.8750\n",
      "Epoch 159/200\n",
      " - 0s - loss: 1.1036 - acc: 0.8750\n",
      "Epoch 160/200\n",
      " - 0s - loss: 1.0951 - acc: 0.8750\n",
      "Epoch 161/200\n",
      " - 0s - loss: 1.0867 - acc: 0.8750\n",
      "Epoch 162/200\n",
      " - 0s - loss: 1.0784 - acc: 0.8750\n",
      "Epoch 163/200\n",
      " - 0s - loss: 1.0701 - acc: 0.8750\n",
      "Epoch 164/200\n",
      " - 0s - loss: 1.0618 - acc: 0.8750\n",
      "Epoch 165/200\n",
      " - 0s - loss: 1.0536 - acc: 0.8750\n",
      "Epoch 166/200\n",
      " - 0s - loss: 1.0454 - acc: 0.8750\n",
      "Epoch 167/200\n",
      " - 0s - loss: 1.0372 - acc: 0.8750\n",
      "Epoch 168/200\n",
      " - 0s - loss: 1.0291 - acc: 0.8750\n",
      "Epoch 169/200\n",
      " - 0s - loss: 1.0211 - acc: 0.8750\n",
      "Epoch 170/200\n",
      " - 0s - loss: 1.0131 - acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      " - 0s - loss: 1.0051 - acc: 0.8750\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.9972 - acc: 0.8750\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.9893 - acc: 0.8750\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.9815 - acc: 0.8750\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.9737 - acc: 0.8750\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.9660 - acc: 0.8750\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.9583 - acc: 0.8750\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.9507 - acc: 0.8750\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.9431 - acc: 0.8750\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.9356 - acc: 0.8750\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.9281 - acc: 0.8750\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.9207 - acc: 0.8750\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.9133 - acc: 0.8750\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.9060 - acc: 0.8750\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.8987 - acc: 0.8750\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.8915 - acc: 0.8750\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.8844 - acc: 0.8750\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.8773 - acc: 0.8750\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.8702 - acc: 0.8750\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.8632 - acc: 0.8750\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.8563 - acc: 0.8750\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.8494 - acc: 0.8750\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.8426 - acc: 0.8750\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.8359 - acc: 0.8750\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.8292 - acc: 0.8750\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.8225 - acc: 0.8750\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.8159 - acc: 0.8750\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.8094 - acc: 0.8750\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.8029 - acc: 0.8750\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.7965 - acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2228e25b860>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size2, 9, input_length = 1))\n",
    "model.add(SimpleRNN(9))\n",
    "model.add(Dense(size2, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X, y , epochs = 200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t2, current_word, n) :\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "    for _ in range(n) : #n번 반복\n",
    "        encoded = t2.texts_to_sequences([current_word])[0]\n",
    "        encoded = np.array(encoded)\n",
    "        result = model.predict_classes(encoded, verbose = 0)\n",
    "        for word, index in t2.word_index.items() :\n",
    "            if index == result :\n",
    "                break\n",
    "        current_word = word\n",
    "        sentence = sentence + ' ' + word\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'먹으러 갈래 메뉴는 햄버거 점심 메뉴 좋지 점심 메뉴 좋지'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model,t2,'먹으러',9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 실습\n",
    "- 뉴욕 타임즈 기사의 제목 데이터 사용\n",
    "- https://www.kaggle.com/aashita/nyt-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ArticlesApril2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount  \\\n",
       "0  5adf6684068401528a2aa69b               781   \n",
       "1  5adf653f068401528a2aa697               656   \n",
       "2  5adf4626068401528a2aa628              2427   \n",
       "3  5adf40d2068401528a2aa619               626   \n",
       "4  5adf3d64068401528a2aa60f               815   \n",
       "\n",
       "                                      byline documentType  \\\n",
       "0                             By JOHN BRANCH      article   \n",
       "1                           By LISA FRIEDMAN      article   \n",
       "2                              By PETE WELLS      article   \n",
       "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
       "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                            keywords  multimedia     newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
       "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
       "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "3          0  2018-04-24 14:35:57        Europe   \n",
       "4          0  2018-04-24 14:21:21        Canada   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
       "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
       "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
       "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
       "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
       "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = []\n",
    "headline.extend(list(df.headline.values))\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1324"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = [i for i in headline if i!=\"Unknown\"]\n",
    "len(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#구두점 제거와 단어의 소문자화\n",
    "from string import punctuation\n",
    "def repreprocessing(s) :\n",
    "    s = s.encode(\"utf8\").decode(\"ascii\", 'ignore')\n",
    "    return ''.join(c for c in s if c not in punctuation).lower()\n",
    "\n",
    "text = [repreprocessing(x) for x in headline]\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 3494\n"
     ]
    }
   ],
   "source": [
    "#단어 집합 만들기\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print('단어 집합의 크기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정수 인코딩을 수행하는 동시에 하나의 문장을 여러 줄로 분해\n",
    "sequences = list()\n",
    "\n",
    "for line in text :\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)) :\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "sequences[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goodell'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#어떤 정수가 어떤 단어를 의미하는지 알아보기 위해 인덱스로부터 단어를 찾아주기\n",
    "\n",
    "index_to_word = {}\n",
    "for key, value in t.word_index.items() :\n",
    "    index_to_word[value] = key\n",
    "\n",
    "index_to_word[1116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(len(i) for i in sequences)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   99  269]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   99  269  371]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   99  269  371 1115]]\n"
     ]
    }
   ],
   "source": [
    "#모든 데이터의 길이를 24로 맞추기\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X와 y 데이터 분리\n",
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# y에 대한 원-핫 인코딩 수행\n",
    "y = to_categorical(y, num_classes = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      " - 12s - loss: 7.6368 - acc: 0.0309\n",
      "Epoch 2/200\n",
      " - 9s - loss: 7.1132 - acc: 0.0309\n",
      "Epoch 3/200\n",
      " - 10s - loss: 6.9750 - acc: 0.0337\n",
      "Epoch 4/200\n",
      " - 10s - loss: 6.8336 - acc: 0.0418\n",
      "Epoch 5/200\n",
      " - 10s - loss: 6.6624 - acc: 0.0469\n",
      "Epoch 6/200\n",
      " - 10s - loss: 6.4727 - acc: 0.0488\n",
      "Epoch 7/200\n",
      " - 10s - loss: 6.2762 - acc: 0.0528\n",
      "Epoch 8/200\n",
      " - 10s - loss: 6.0757 - acc: 0.0578\n",
      "Epoch 9/200\n",
      " - 10s - loss: 5.8798 - acc: 0.0614\n",
      "Epoch 10/200\n",
      " - 11s - loss: 5.6902 - acc: 0.0695\n",
      "Epoch 11/200\n",
      " - 11s - loss: 5.5123 - acc: 0.0727\n",
      "Epoch 12/200\n",
      " - 10s - loss: 5.3409 - acc: 0.0764\n",
      "Epoch 13/200\n",
      " - 11s - loss: 5.1796 - acc: 0.0820\n",
      "Epoch 14/200\n",
      " - 11s - loss: 5.0197 - acc: 0.0901\n",
      "Epoch 15/200\n",
      " - 11s - loss: 4.8677 - acc: 0.1003\n",
      "Epoch 16/200\n",
      " - 11s - loss: 4.7262 - acc: 0.1111\n",
      "Epoch 17/200\n",
      " - 11s - loss: 4.5840 - acc: 0.1284\n",
      "Epoch 18/200\n",
      " - 11s - loss: 4.4521 - acc: 0.1437\n",
      "Epoch 19/200\n",
      " - 11s - loss: 4.3215 - acc: 0.1643\n",
      "Epoch 20/200\n",
      " - 11s - loss: 4.1975 - acc: 0.1794\n",
      "Epoch 21/200\n",
      " - 11s - loss: 4.0757 - acc: 0.2015\n",
      "Epoch 22/200\n",
      " - 11s - loss: 3.9584 - acc: 0.2159\n",
      "Epoch 23/200\n",
      " - 11s - loss: 3.8436 - acc: 0.2368\n",
      "Epoch 24/200\n",
      " - 11s - loss: 3.7360 - acc: 0.2529\n",
      "Epoch 25/200\n",
      " - 11s - loss: 3.6324 - acc: 0.2719\n",
      "Epoch 26/200\n",
      " - 11s - loss: 3.5339 - acc: 0.2931\n",
      "Epoch 27/200\n",
      " - 11s - loss: 3.4343 - acc: 0.3083\n",
      "Epoch 28/200\n",
      " - 11s - loss: 3.3402 - acc: 0.3271\n",
      "Epoch 29/200\n",
      " - 11s - loss: 3.2513 - acc: 0.3345\n",
      "Epoch 30/200\n",
      " - 12s - loss: 3.1680 - acc: 0.3533\n",
      "Epoch 31/200\n",
      " - 12s - loss: 3.0853 - acc: 0.3699\n",
      "Epoch 32/200\n",
      " - 11s - loss: 3.0058 - acc: 0.3793\n",
      "Epoch 33/200\n",
      " - 12s - loss: 2.9301 - acc: 0.3974\n",
      "Epoch 34/200\n",
      " - 12s - loss: 2.8577 - acc: 0.4151\n",
      "Epoch 35/200\n",
      " - 12s - loss: 2.7883 - acc: 0.4227\n",
      "Epoch 36/200\n",
      " - 12s - loss: 2.7215 - acc: 0.4360\n",
      "Epoch 37/200\n",
      " - 12s - loss: 2.6559 - acc: 0.4489\n",
      "Epoch 38/200\n",
      " - 12s - loss: 2.5914 - acc: 0.4617\n",
      "Epoch 39/200\n",
      " - 12s - loss: 2.5297 - acc: 0.4733\n",
      "Epoch 40/200\n",
      " - 12s - loss: 2.4715 - acc: 0.4858\n",
      "Epoch 41/200\n",
      " - 12s - loss: 2.4127 - acc: 0.4949\n",
      "Epoch 42/200\n",
      " - 12s - loss: 2.3558 - acc: 0.5079\n",
      "Epoch 43/200\n",
      " - 12s - loss: 2.3038 - acc: 0.5154\n",
      "Epoch 44/200\n",
      " - 12s - loss: 2.2509 - acc: 0.5261\n",
      "Epoch 45/200\n",
      " - 12s - loss: 2.1964 - acc: 0.5377\n",
      "Epoch 46/200\n",
      " - 12s - loss: 2.1507 - acc: 0.5484\n",
      "Epoch 47/200\n",
      " - 12s - loss: 2.1006 - acc: 0.5565\n",
      "Epoch 48/200\n",
      " - 12s - loss: 2.0540 - acc: 0.5689\n",
      "Epoch 49/200\n",
      " - 12s - loss: 2.0045 - acc: 0.5766\n",
      "Epoch 50/200\n",
      " - 12s - loss: 1.9587 - acc: 0.5863\n",
      "Epoch 51/200\n",
      " - 12s - loss: 1.9120 - acc: 0.5962\n",
      "Epoch 52/200\n",
      " - 12s - loss: 1.8730 - acc: 0.6059\n",
      "Epoch 53/200\n",
      " - 12s - loss: 1.8295 - acc: 0.6131\n",
      "Epoch 54/200\n",
      " - 12s - loss: 1.7891 - acc: 0.6231\n",
      "Epoch 55/200\n",
      " - 12s - loss: 1.7497 - acc: 0.6322\n",
      "Epoch 56/200\n",
      " - 12s - loss: 1.7076 - acc: 0.6423\n",
      "Epoch 57/200\n",
      " - 12s - loss: 1.6669 - acc: 0.6510\n",
      "Epoch 58/200\n",
      " - 12s - loss: 1.6305 - acc: 0.6605\n",
      "Epoch 59/200\n",
      " - 12s - loss: 1.5965 - acc: 0.6685\n",
      "Epoch 60/200\n",
      " - 12s - loss: 1.5588 - acc: 0.6769\n",
      "Epoch 61/200\n",
      " - 12s - loss: 1.5259 - acc: 0.6823\n",
      "Epoch 62/200\n",
      " - 12s - loss: 1.4900 - acc: 0.6911\n",
      "Epoch 63/200\n",
      " - 12s - loss: 1.4563 - acc: 0.6931\n",
      "Epoch 64/200\n",
      " - 12s - loss: 1.4254 - acc: 0.7058\n",
      "Epoch 65/200\n",
      " - 13s - loss: 1.3907 - acc: 0.7128\n",
      "Epoch 66/200\n",
      " - 13s - loss: 1.3627 - acc: 0.7182\n",
      "Epoch 67/200\n",
      " - 13s - loss: 1.3294 - acc: 0.7277\n",
      "Epoch 68/200\n",
      " - 13s - loss: 1.2992 - acc: 0.7310\n",
      "Epoch 69/200\n",
      " - 13s - loss: 1.2700 - acc: 0.7382\n",
      "Epoch 70/200\n",
      " - 13s - loss: 1.2455 - acc: 0.7428\n",
      "Epoch 71/200\n",
      " - 13s - loss: 1.2175 - acc: 0.7504\n",
      "Epoch 72/200\n",
      " - 13s - loss: 1.1896 - acc: 0.7582\n",
      "Epoch 73/200\n",
      " - 13s - loss: 1.1632 - acc: 0.7621\n",
      "Epoch 74/200\n",
      " - 13s - loss: 1.1393 - acc: 0.7660\n",
      "Epoch 75/200\n",
      " - 13s - loss: 1.1136 - acc: 0.7735\n",
      "Epoch 76/200\n",
      " - 13s - loss: 1.0910 - acc: 0.7776\n",
      "Epoch 77/200\n",
      " - 13s - loss: 1.0607 - acc: 0.7821\n",
      "Epoch 78/200\n",
      " - 13s - loss: 1.0403 - acc: 0.7888\n",
      "Epoch 79/200\n",
      " - 13s - loss: 1.0200 - acc: 0.7933\n",
      "Epoch 80/200\n",
      " - 13s - loss: 0.9973 - acc: 0.8015\n",
      "Epoch 81/200\n",
      " - 13s - loss: 0.9755 - acc: 0.8021\n",
      "Epoch 82/200\n",
      " - 13s - loss: 0.9550 - acc: 0.8055\n",
      "Epoch 83/200\n",
      " - 13s - loss: 0.9364 - acc: 0.8065\n",
      "Epoch 84/200\n",
      " - 13s - loss: 0.9181 - acc: 0.8129\n",
      "Epoch 85/200\n",
      " - 13s - loss: 0.8923 - acc: 0.8181\n",
      "Epoch 86/200\n",
      " - 13s - loss: 0.8730 - acc: 0.8205\n",
      "Epoch 87/200\n",
      " - 13s - loss: 0.8552 - acc: 0.8266\n",
      "Epoch 88/200\n",
      " - 13s - loss: 0.8366 - acc: 0.8308\n",
      "Epoch 89/200\n",
      " - 13s - loss: 0.8201 - acc: 0.8334\n",
      "Epoch 90/200\n",
      " - 13s - loss: 0.8025 - acc: 0.8361\n",
      "Epoch 91/200\n",
      " - 13s - loss: 0.7833 - acc: 0.8404\n",
      "Epoch 92/200\n",
      " - 13s - loss: 0.7701 - acc: 0.8472\n",
      "Epoch 93/200\n",
      " - 13s - loss: 0.7504 - acc: 0.8488\n",
      "Epoch 94/200\n",
      " - 13s - loss: 0.7381 - acc: 0.8511\n",
      "Epoch 95/200\n",
      " - 13s - loss: 0.7221 - acc: 0.8547\n",
      "Epoch 96/200\n",
      " - 13s - loss: 0.7133 - acc: 0.8575\n",
      "Epoch 97/200\n",
      " - 13s - loss: 0.6953 - acc: 0.8584\n",
      "Epoch 98/200\n",
      " - 13s - loss: 0.6816 - acc: 0.8648\n",
      "Epoch 99/200\n",
      " - 13s - loss: 0.6633 - acc: 0.8643\n",
      "Epoch 100/200\n",
      " - 13s - loss: 0.6515 - acc: 0.8706\n",
      "Epoch 101/200\n",
      " - 13s - loss: 0.6360 - acc: 0.8716\n",
      "Epoch 102/200\n",
      " - 13s - loss: 0.6269 - acc: 0.8726\n",
      "Epoch 103/200\n",
      " - 13s - loss: 0.6149 - acc: 0.8734\n",
      "Epoch 104/200\n",
      " - 13s - loss: 0.6051 - acc: 0.8749\n",
      "Epoch 105/200\n",
      " - 13s - loss: 0.5913 - acc: 0.8779\n",
      "Epoch 106/200\n",
      " - 13s - loss: 0.5795 - acc: 0.8802\n",
      "Epoch 107/200\n",
      " - 13s - loss: 0.5713 - acc: 0.8834\n",
      "Epoch 108/200\n",
      " - 13s - loss: 0.5572 - acc: 0.8856\n",
      "Epoch 109/200\n",
      " - 13s - loss: 0.5436 - acc: 0.8865\n",
      "Epoch 110/200\n",
      " - 13s - loss: 0.5378 - acc: 0.8897\n",
      "Epoch 111/200\n",
      " - 13s - loss: 0.5380 - acc: 0.8898\n",
      "Epoch 112/200\n",
      " - 13s - loss: 0.5256 - acc: 0.8897\n",
      "Epoch 113/200\n",
      " - 13s - loss: 0.5102 - acc: 0.8926\n",
      "Epoch 114/200\n",
      " - 13s - loss: 0.4985 - acc: 0.8931\n",
      "Epoch 115/200\n",
      " - 14s - loss: 0.4898 - acc: 0.8948\n",
      "Epoch 116/200\n",
      " - 13s - loss: 0.4851 - acc: 0.8947\n",
      "Epoch 117/200\n",
      " - 14s - loss: 0.4764 - acc: 0.8976\n",
      "Epoch 118/200\n",
      " - 14s - loss: 0.4776 - acc: 0.8967\n",
      "Epoch 119/200\n",
      " - 13s - loss: 0.4600 - acc: 0.9006\n",
      "Epoch 120/200\n",
      " - 14s - loss: 0.4524 - acc: 0.9021\n",
      "Epoch 121/200\n",
      " - 13s - loss: 0.4434 - acc: 0.9036\n",
      "Epoch 122/200\n",
      " - 13s - loss: 0.4372 - acc: 0.9031\n",
      "Epoch 123/200\n",
      " - 14s - loss: 0.4313 - acc: 0.9055\n",
      "Epoch 124/200\n",
      " - 13s - loss: 0.4381 - acc: 0.9017\n",
      "Epoch 125/200\n",
      " - 14s - loss: 0.4233 - acc: 0.9066\n",
      "Epoch 126/200\n",
      " - 14s - loss: 0.4153 - acc: 0.9061\n",
      "Epoch 127/200\n",
      " - 14s - loss: 0.4060 - acc: 0.9080\n",
      "Epoch 128/200\n",
      " - 13s - loss: 0.4048 - acc: 0.9070\n",
      "Epoch 129/200\n",
      " - 14s - loss: 0.3980 - acc: 0.9095\n",
      "Epoch 130/200\n",
      " - 14s - loss: 0.3920 - acc: 0.9107\n",
      "Epoch 131/200\n",
      " - 14s - loss: 0.3870 - acc: 0.9100\n",
      "Epoch 132/200\n",
      " - 14s - loss: 0.3873 - acc: 0.9116\n",
      "Epoch 133/200\n",
      " - 14s - loss: 0.3858 - acc: 0.9107\n",
      "Epoch 134/200\n",
      " - 14s - loss: 0.3755 - acc: 0.9118\n",
      "Epoch 135/200\n",
      " - 14s - loss: 0.3701 - acc: 0.9122\n",
      "Epoch 136/200\n",
      " - 14s - loss: 0.3653 - acc: 0.9134\n",
      "Epoch 137/200\n",
      " - 14s - loss: 0.3592 - acc: 0.9129\n",
      "Epoch 138/200\n",
      " - 14s - loss: 0.3846 - acc: 0.9062\n",
      "Epoch 139/200\n",
      " - 14s - loss: 0.3914 - acc: 0.9072\n",
      "Epoch 140/200\n",
      " - 14s - loss: 0.3571 - acc: 0.9134\n",
      "Epoch 141/200\n",
      " - 14s - loss: 0.3444 - acc: 0.9141\n",
      "Epoch 142/200\n",
      " - 14s - loss: 0.3402 - acc: 0.9136\n",
      "Epoch 143/200\n",
      " - 14s - loss: 0.3360 - acc: 0.9152\n",
      "Epoch 144/200\n",
      " - 14s - loss: 0.3343 - acc: 0.9140\n",
      "Epoch 145/200\n",
      " - 14s - loss: 0.3327 - acc: 0.9144\n",
      "Epoch 146/200\n",
      " - 14s - loss: 0.3293 - acc: 0.9152\n",
      "Epoch 147/200\n",
      " - 14s - loss: 0.3269 - acc: 0.9148\n",
      "Epoch 148/200\n",
      " - 15s - loss: 0.3289 - acc: 0.9143\n",
      "Epoch 149/200\n",
      " - 14s - loss: 0.3254 - acc: 0.9163\n",
      "Epoch 150/200\n",
      " - 14s - loss: 0.3290 - acc: 0.9141\n",
      "Epoch 151/200\n",
      " - 14s - loss: 0.3334 - acc: 0.9150\n",
      "Epoch 152/200\n",
      " - 14s - loss: 0.3257 - acc: 0.9148\n",
      "Epoch 153/200\n",
      " - 14s - loss: 0.3271 - acc: 0.9152\n",
      "Epoch 154/200\n",
      " - 14s - loss: 0.3557 - acc: 0.9097\n",
      "Epoch 155/200\n",
      " - 14s - loss: 0.3349 - acc: 0.9127\n",
      "Epoch 156/200\n",
      " - 14s - loss: 0.3136 - acc: 0.9161\n",
      "Epoch 157/200\n",
      " - 14s - loss: 0.3074 - acc: 0.9158\n",
      "Epoch 158/200\n",
      " - 14s - loss: 0.3047 - acc: 0.9162\n",
      "Epoch 159/200\n",
      " - 14s - loss: 0.3036 - acc: 0.9145\n",
      "Epoch 160/200\n",
      " - 14s - loss: 0.3013 - acc: 0.9179\n",
      "Epoch 161/200\n",
      " - 14s - loss: 0.2999 - acc: 0.9164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200\n",
      " - 14s - loss: 0.3002 - acc: 0.9163\n",
      "Epoch 163/200\n",
      " - 14s - loss: 0.3005 - acc: 0.9148\n",
      "Epoch 164/200\n",
      " - 16s - loss: 0.3084 - acc: 0.9136\n",
      "Epoch 165/200\n",
      " - 16s - loss: 0.2988 - acc: 0.9170\n",
      "Epoch 166/200\n",
      " - 15s - loss: 0.3038 - acc: 0.9146\n",
      "Epoch 167/200\n",
      " - 14s - loss: 0.3394 - acc: 0.9108\n",
      "Epoch 168/200\n",
      " - 14s - loss: 0.3099 - acc: 0.9153\n",
      "Epoch 169/200\n",
      " - 14s - loss: 0.2991 - acc: 0.9161\n",
      "Epoch 170/200\n",
      " - 14s - loss: 0.2911 - acc: 0.9167\n",
      "Epoch 171/200\n",
      " - 14s - loss: 0.2911 - acc: 0.9148\n",
      "Epoch 172/200\n",
      " - 14s - loss: 0.2884 - acc: 0.9167\n",
      "Epoch 173/200\n",
      " - 14s - loss: 0.2875 - acc: 0.9155\n",
      "Epoch 174/200\n",
      " - 14s - loss: 0.2856 - acc: 0.9163\n",
      "Epoch 175/200\n",
      " - 14s - loss: 0.2855 - acc: 0.9168\n",
      "Epoch 176/200\n",
      " - 14s - loss: 0.2860 - acc: 0.9150\n",
      "Epoch 177/200\n",
      " - 14s - loss: 0.2888 - acc: 0.9150\n",
      "Epoch 178/200\n",
      " - 14s - loss: 0.2971 - acc: 0.9150\n",
      "Epoch 179/200\n",
      " - 14s - loss: 0.2866 - acc: 0.9172\n",
      "Epoch 180/200\n",
      " - 14s - loss: 0.2847 - acc: 0.9173\n",
      "Epoch 181/200\n",
      " - 14s - loss: 0.2816 - acc: 0.9162\n",
      "Epoch 182/200\n",
      " - 14s - loss: 0.2816 - acc: 0.9158\n",
      "Epoch 183/200\n",
      " - 14s - loss: 0.2817 - acc: 0.9154\n",
      "Epoch 184/200\n",
      " - 14s - loss: 0.2797 - acc: 0.9172\n",
      "Epoch 185/200\n",
      " - 15s - loss: 0.2942 - acc: 0.9141\n",
      "Epoch 186/200\n",
      " - 14s - loss: 0.2974 - acc: 0.9125\n",
      "Epoch 187/200\n",
      " - 14s - loss: 0.2890 - acc: 0.9152\n",
      "Epoch 188/200\n",
      " - 14s - loss: 0.2796 - acc: 0.9163\n",
      "Epoch 189/200\n",
      " - 15s - loss: 0.2770 - acc: 0.9166\n",
      "Epoch 190/200\n",
      " - 14s - loss: 0.2735 - acc: 0.9166\n",
      "Epoch 191/200\n",
      " - 14s - loss: 0.2739 - acc: 0.9163\n",
      "Epoch 192/200\n",
      " - 14s - loss: 0.2751 - acc: 0.9162\n",
      "Epoch 193/200\n",
      " - 14s - loss: 0.2735 - acc: 0.9153\n",
      "Epoch 194/200\n",
      " - 14s - loss: 0.2713 - acc: 0.9163\n",
      "Epoch 195/200\n",
      " - 15s - loss: 0.2714 - acc: 0.9180\n",
      "Epoch 196/200\n",
      " - 14s - loss: 0.2714 - acc: 0.9155\n",
      "Epoch 197/200\n",
      " - 14s - loss: 0.2716 - acc: 0.9175\n",
      "Epoch 198/200\n",
      " - 14s - loss: 0.2702 - acc: 0.9166\n",
      "Epoch 199/200\n",
      " - 14s - loss: 0.2750 - acc: 0.9158\n",
      "Epoch 200/200\n",
      " - 14s - loss: 0.2745 - acc: 0.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219d4036fd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, 10, input_length = max_len-1))\n",
    "model2.add(LSTM(128))\n",
    "model2.add(Dense(vocab_size, activation='softmax'))\n",
    "model2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model2.fit(X, y, epochs = 200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how to beat the americans season more pruitt the americans season'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_generation(model, t, current_word, n) :\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "    for _ in range(n) : #n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=23, padding='pre')\n",
    "        result = model.predict_classes(encoded, verbose = 0)\n",
    "        for word, index in t.word_index.items() :\n",
    "            if index == result :\n",
    "                break\n",
    "        current_word = word\n",
    "        sentence = sentence + ' ' + word\n",
    "    sentence = init_word + sentence\n",
    "    return sentence\n",
    "\n",
    "sentence_generation(model2, t, 'how',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what the americans season more pruitt the americans season more pruitt the americans season more pruitt the americans season more pruitt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model2, t, 'what',20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hikeras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
